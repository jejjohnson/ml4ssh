{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d67b99-71be-4f66-9397-b15b60ee0226",
   "metadata": {},
   "source": [
    "# NerF + QG Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59583528-46e3-4e59-99c6-338029736d60",
   "metadata": {},
   "source": [
    "The full QG equation is given by:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\partial_t q + \\det \\boldsymbol{J}(q, \\psi) &= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $q=\\nabla^2 \\psi$\n",
    "* $\\det \\boldsymbol{J}(q, \\psi)=\\partial_x q\\partial_y\\psi - \\partial_y q\\partial_x\\psi$.\n",
    "\n",
    "We are interested in finding some NerF method that can take in the spatial-temporal coordinates, $\\mathbf{x}_\\phi$, and output a vector corresponding to the PV and stream function, $\\psi$, i.e. $\\mathbf{y}_\\text{obs}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_\\text{obs} = \\boldsymbol{f_\\theta}(\\mathbf{x}_\\phi) + \\epsilon, \\hspace{5mm}\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "We use a SIREN network which is a fully connected neural network with the $sin$ activation function.\n",
    "\n",
    "* **Data Inputs**: `256x256x11`\n",
    "* **Data Ouputs**: `2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d850f86-a38d-41f6-972c-4ecb70a3af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".root\"])\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from ml_collections import config_dict\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "pl.seed_everything(123)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from config_1 import get_config\n",
    "\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975fa36-64cc-4848-938a-3c1cdd14b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml_collections import config_dict\n",
    "\n",
    "# cfg = config_dict.ConfigDict()\n",
    "\n",
    "# # logging args\n",
    "# cfg.log = config_dict.ConfigDict()\n",
    "# cfg.log.mode = \"online\" #\"disabled\"\n",
    "# cfg.log.project =\"inr4ssh\"\n",
    "# cfg.log.entity = \"ige\"\n",
    "# cfg.log.log_dir = \"/Users/eman/code_projects/logs/\"\n",
    "# cfg.log.resume = False\n",
    "\n",
    "# # data args\n",
    "# cfg.data = config_dict.ConfigDict()\n",
    "# cfg.data.data_dir =  f\"/Users/eman/code_projects/torchqg/data/qgsim_simple_128x128.nc\"\n",
    "\n",
    "# # preprocessing args\n",
    "# cfg.pre = config_dict.ConfigDict()\n",
    "# cfg.pre.noise = 0.01\n",
    "# cfg.pre.dt = 1.0\n",
    "# cfg.pre.time_min = 500\n",
    "# cfg.pre.time_max = 511\n",
    "# cfg.pre.seed = 123\n",
    "\n",
    "# # train/test args\n",
    "# cfg.split = config_dict.ConfigDict()\n",
    "# cfg.split.train_prct = 0.9\n",
    "\n",
    "# # dataloader args\n",
    "# cfg.dl = config_dict.ConfigDict()\n",
    "# cfg.dl.batchsize_train = 2048\n",
    "# cfg.dl.batchsize_val = 1_000\n",
    "# cfg.dl.batchsize_test = 5_000\n",
    "# cfg.dl.batchsize_predict = 10_000\n",
    "# cfg.dl.num_workers = 0\n",
    "# cfg.dl.pin_memory = False\n",
    "\n",
    "# # loss arguments\n",
    "# cfg.loss = config_dict.ConfigDict()\n",
    "# cfg.loss.qg = True\n",
    "# cfg.loss.alpha = 1e-4\n",
    "\n",
    "# # optimizer args\n",
    "# cfg.optim = config_dict.ConfigDict()\n",
    "# cfg.optim.warmup = 10\n",
    "# cfg.optim.num_epochs = 100\n",
    "# cfg.optim.learning_rate = 1e-4\n",
    "\n",
    "# # trainer args\n",
    "# cfg.trainer = config_dict.ConfigDict()\n",
    "# cfg.trainer.accelerator = None\n",
    "# cfg.trainer.devices = 1\n",
    "# cfg.trainer.grad_batches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac47ef1-8d2d-4e12-8f17-fc53fe4a5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.io import transform_dict\n",
    "\n",
    "cfg = get_config()\n",
    "\n",
    "cfg.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788b8f2-9941-4da8-b906-038115cb8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    config=cfg.to_dict(),\n",
    "    mode=\"offline\",  # cfg.log.mode,\n",
    "    project=cfg.log.project,\n",
    "    entity=cfg.log.entity,\n",
    "    dir=cfg.log.log_dir,\n",
    "    resume=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Users/eman/code_projects/torchqg/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4858b20-4c08-496b-aa14-64d72cc6b65f",
   "metadata": {},
   "source": [
    "## Data Module\n",
    "\n",
    "Now we will put all of the preprocessing routines together. This is **very important** for a few reasons:\n",
    "\n",
    "1. It collapses all of the operations in a modular way\n",
    "2. It makes it reproducible for the next people\n",
    "3. It makes it very easy for the PyTorch-Lightning framework down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da06ade-90f7-41ad-9165-6c05a876f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e0af1-1243-48d1-b593-80be9cde3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputScalingTransform(nn.Module):\n",
    "    def __init__(self, x_min, x_max):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_buffer(\"x_min\", torch.FloatTensor(x_min))\n",
    "        self.register_buffer(\"x_max\", torch.FloatTensor(x_max))\n",
    "\n",
    "    def forward(self, x, inverse=False):\n",
    "        if not inverse:\n",
    "            return self.transform(x)\n",
    "        else:\n",
    "            return self.inverse_transform(x)\n",
    "\n",
    "    def transform(self, x):\n",
    "        return (x - self.x_min) / (self.x_max - self.x_min)\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        return x * (self.x_max - self.x_min) + self.x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75257127-cb80-43d1-9d5a-16e0fa50a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGSimulation(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # load data\n",
    "        data = xr.open_dataset(self.config.data.data_dir, engine=\"netcdf4\")\n",
    "\n",
    "        data_df = data.to_dataframe().reset_index()\n",
    "\n",
    "        # subset variables of interest\n",
    "        x_df = data_df[[\"Nx\", \"Ny\", \"steps\"]]\n",
    "        y_df = data_df[[\"p\"]]\n",
    "\n",
    "        # get spatial/temporal min/max limits\n",
    "        x_min = x_df.min(axis=0)\n",
    "        x_max = x_df.max(axis=0)\n",
    "\n",
    "        # create invertible transformation\n",
    "        transform = InputScalingTransform(x_min.values, x_max.values)\n",
    "        self.transform = transform\n",
    "\n",
    "        # create prediction dataset (everything)\n",
    "        predict_ds = TensorDataset(\n",
    "            torch.FloatTensor(x_df.values), torch.FloatTensor(y_df.values)\n",
    "        )\n",
    "\n",
    "        # create train/val/test datasets\n",
    "        n_datapoints = len(predict_ds)\n",
    "        train_split = int(self.config.split.train_prct * n_datapoints)\n",
    "        valid_split = n_datapoints - train_split\n",
    "\n",
    "        # random split\n",
    "        train_ds, valid_ds = torch.utils.data.random_split(\n",
    "            predict_ds, (train_split, valid_split)\n",
    "        )\n",
    "\n",
    "        self.ds_train = train_ds\n",
    "        self.ds_valid = valid_ds\n",
    "        self.ds_predict = predict_ds\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds_train,\n",
    "            batch_size=self.config.dl.batchsize_train,\n",
    "            shuffle=True,\n",
    "            num_workers=self.config.dl.num_workers,\n",
    "            pin_memory=self.config.dl.pin_memory,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds_valid,\n",
    "            batch_size=self.config.dl.batchsize_val,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.dl.num_workers,\n",
    "            pin_memory=self.config.dl.pin_memory,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds_predict,\n",
    "            batch_size=self.config.dl.batchsize_test,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.dl.num_workers,\n",
    "            pin_memory=self.config.dl.pin_memory,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds_predict,\n",
    "            batch_size=self.config.dl.batchsize_predict,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.dl.num_workers,\n",
    "            pin_memory=self.config.dl.pin_memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da7217-f0a7-42b9-9351-db849446c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = QGSimulation(cfg)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924f943-f3bd-481c-9e20-e1fc9403aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init, y_init = dm.ds_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14ad86-9688-4d02-8fa8-5e691763a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init.shape, y_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a68f60-19d7-439e-988b-8a99263ee269",
   "metadata": {},
   "source": [
    "## NerF\n",
    "\n",
    "This standard Neural Fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a5668-1ac3-440c-bc8c-5fbbc485ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.models.siren import Siren, SirenNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f1b7f-e81c-4f96-a310-f766872f0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = x_init.shape[1]\n",
    "dim_hidden = 256\n",
    "dim_out = y_init.shape[1]\n",
    "num_layers = 4\n",
    "w0 = 1.0\n",
    "w0_initial = 30.0\n",
    "c = 6.0\n",
    "final_activation = None  # nn.Sigmoid()\n",
    "\n",
    "net = SirenNet(\n",
    "    dim_in=dim_in,\n",
    "    dim_hidden=dim_hidden,\n",
    "    dim_out=dim_out,\n",
    "    num_layers=num_layers,\n",
    "    w0=w0,\n",
    "    w0_initial=w0_initial,\n",
    "    c=c,\n",
    "    final_activation=final_activation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8b3c9-60a0-4cea-89f9-8f16daf2b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(x_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a5b16-265f-4aa9-9ac8-7316fcbdfa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98a0ab8-3e63-44f1-98d7-3a5541e2ab9c",
   "metadata": {},
   "source": [
    "## PINNS Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4409bd4-cbce-4308-9425-587a2382db84",
   "metadata": {},
   "source": [
    "$$\n",
    "\\partial_t \\nabla^2 \\psi + \\det J(\\psi, \\nabla^2\\psi) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d099c57-9f81-445b-8870-5429d1caa3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.operators import differential_simp as diffops_simp\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bcc820-3187-4579-87fb-cd5c0daef320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegQG(nn.Module):\n",
    "    def __init__(self, alpha: float = 1e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        alpha = torch.Tensor([alpha])\n",
    "\n",
    "        self.register_buffer(\"alpha\", alpha)\n",
    "\n",
    "    def forward(self, x, f):\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "\n",
    "            x = torch.autograd.Variable(x, requires_grad=True)\n",
    "\n",
    "            u = f(x)\n",
    "\n",
    "            grad_nn = diffops_simp.gradient(u, x)\n",
    "            q_nn = diffops_simp.divergence(grad_nn, x)\n",
    "            dlaplacU = diffops_simp.gradient(q_nn, x)\n",
    "            Jacob_U_laplacU = (\n",
    "                grad_nn[:, 1] * dlaplacU[:, 2] - grad_nn[:, 2] * dlaplacU[:, 1]\n",
    "            )\n",
    "\n",
    "            pde_loss = F.mse_loss(\n",
    "                dlaplacU[:, 0] + Jacob_U_laplacU, torch.zeros_like(Jacob_U_laplacU)\n",
    "            )\n",
    "            return self.alpha * pde_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d619e-b6f9-4e11-88e3-eec1665eb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_loss = RegQG(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6214a0-7a2c-4a4a-9930-61756970a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_loss(x_init, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7ab29-f515-465d-a4c5-1f786806008e",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5ee8c-a204-48dc-a47f-fbc66d88646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from functools import partial\n",
    "from typing import Dict, Any, cast\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35508e0c-bdf9-4909-b898-208a2617daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class INRModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        reg_pde,\n",
    "        optimizer: str = \"adam\",\n",
    "        qg: bool = True,\n",
    "        alpha: float = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.hyperparams = cast(Dict[str, Any], self.hparams)\n",
    "        self.loss_data = nn.MSELoss(reduction=\"mean\")\n",
    "        self.reg_pde = RegQG(self.hyperparams.get(\"alpha\", 1e-4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _data_loss(self, batch):\n",
    "        x, y = batch\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        # parse inputs\n",
    "        x, y = batch\n",
    "\n",
    "        # data loss function\n",
    "        loss = self.loss_data(y, pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _qg_loss(self, batch):\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        loss = self.reg_pde.forward(x, self.model)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # loss function\n",
    "        loss_data = self._data_loss(batch)\n",
    "\n",
    "        if self.hyperparams.get(\"qg\", False):\n",
    "            # x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            # out = self.forward(x_var)\n",
    "            # reg = qg_loss(out, x_var, 1.0, 1.0, 1.0, \"mean\")\n",
    "            loss_reg = self._qg_loss(batch)\n",
    "\n",
    "            loss = loss_data + loss_reg\n",
    "\n",
    "            self.log(\"train_reg\", loss_reg, prog_bar=True)\n",
    "            self.log(\"train_data\", loss_data, prog_bar=True)\n",
    "        else:\n",
    "            loss = loss_data\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        # loss function\n",
    "        loss_data = self._data_loss(batch)\n",
    "\n",
    "        if self.hyperparams.get(\"qg\", False):\n",
    "            # x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            # out = self.forward(x_var)\n",
    "            # reg = qg_loss(out, x_var, 1.0, 1.0, 1.0, \"mean\")\n",
    "            loss_reg = self._qg_loss(batch)\n",
    "\n",
    "            loss = loss_data + loss_reg\n",
    "\n",
    "            self.log(\"train_reg\", loss_reg, prog_bar=True)\n",
    "            self.log(\"train_data\", loss_data, prog_bar=True)\n",
    "        else:\n",
    "            loss = loss_data\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        # loss function\n",
    "        loss_data = self._data_loss(batch)\n",
    "\n",
    "        if self.hyperparams.get(\"qg\", False):\n",
    "            # x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            # out = self.forward(x_var)\n",
    "            # reg = qg_loss(out, x_var, 1.0, 1.0, 1.0, \"mean\")\n",
    "            loss_reg = self._qg_loss(batch)\n",
    "\n",
    "            loss = loss_data + loss_reg\n",
    "\n",
    "            self.log(\"train_reg\", loss_reg, prog_bar=True)\n",
    "            self.log(\"train_data\", loss_data, prog_bar=True)\n",
    "        else:\n",
    "            loss = loss_data\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # output\n",
    "        x, y = batch\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # configure optimizer\n",
    "        optimizer = Adam(self.model.parameters(), lr=self.hyperparams.get(\"lr\", 1e-4))\n",
    "\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer,\n",
    "            warmup_epochs=self.hyperparams.get(\"warmup\", 10),\n",
    "            max_epochs=self.hyperparams.get(\"num_epochs\", 100),\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe37d1-9ba0-4c06-855d-2eacb9280d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"ige/inr4ssh/1st3rtl0\"\n",
    "model_path = \"checkpoints/epoch=990-step=39640.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641689c3-858f-47d3-8a5a-d0a5f51d3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.io import get_wandb_config, get_wandb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a42b7-4c8b-4bc8-8615-bed4076bad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = get_wandb_model(run_path, model_path)\n",
    "best_model.download(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614a086-9047-409a-bca0-a6c5f5397560",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb6f69-6ac9-4c63-92c3-5cba761c4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import TQDMProgressBar, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49aef1-e25b-439e-b7ba-32bfa9156080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b3719-950a-4451-854f-7e1be116d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcda2a4-ed6a-4f00-a5f7-c91a370a33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb = ModelCheckpoint(\n",
    "    dirpath=str(Path(wandb_logger.experiment.dir).joinpath(\"checkpoints\")),\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d01235-05c7-4419-bbdf-c297290d810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [model_cb, TQDMProgressBar(refresh_rate=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918f2c6-d8aa-4e61-8032-eac90a02f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac691f0e-8563-466b-ba03-aa5e036a6937",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d74bf-df3e-4040-ade6-3ed1f60b2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(best_model.name, map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399d34e-0378-48cc-ab22-3c59f99accad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ed1c2-f45e-474b-94cd-d296b21d72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac1925-e2cf-4f54-9197-5d245057f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e95d4-5df7-4a3c-a10a-a7bb2541e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs,\n",
    "net = SirenNet(**kwargs)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc1e9f-5399-4c5e-90a8-1ef3214b067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.qg.qg_sim.model import INRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764224d-c5f7-4811-bc90-95a7e52d2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = INRModel.load_from_checkpoint(\n",
    "    best_model.name,\n",
    "    model=net,\n",
    "    loss_data=nn.MSELoss(\"mean\"),\n",
    "    reg_pde=reg_loss,\n",
    "    learning_rate=cfg.optim.learning_rate,\n",
    "    warmup=cfg.optim.warmup,\n",
    "    num_epochs=cfg.optim.num_epochs,\n",
    "    alpha=cfg.loss.alpha,\n",
    "    qg=cfg.loss.qg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94dae0-3f14-471b-bb82-5206b862d5ad",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58be52-50e3-4072-82c4-7ef17fb24fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    min_epochs=1,\n",
    "    max_epochs=cfg.optim.num_epochs,\n",
    "    accelerator=cfg.trainer.accelerator,\n",
    "    devices=cfg.trainer.devices,\n",
    "    enable_progress_bar=True,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    accumulate_grad_batches=cfg.trainer.grad_batches,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd7117-e4db-426f-b470-bfb22c424570",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889c892-20c6-4446-8818-f8b7a6df9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    learn,\n",
    "    datamodule=dm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054fa4be-b7ca-4265-b629-3b0d89bdc18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e87e6b4-1d97-4d5d-a00b-2c14b28677e0",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7dc94-9401-46b7-99dd-9643352951e0",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb782e-493c-43cb-a481-9a36bdf33045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = trainer.test(learn, dataloaders=dm.test_dataloader())\n",
    "\n",
    "# results[\"data\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923b2c1-0b0d-47de-9940-3e020d5b2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e93692-f60c-457a-b483-eb7a8da4d771",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b77091-4ca8-4084-9bc3-a2eb75ae545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "predictions = trainer.predict(learn, datamodule=dm, return_predictions=True)\n",
    "predictions = torch.cat(predictions)\n",
    "# t1 = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accfbe4-5fbf-4158-8ef2-8cc3bb09c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred = dm.create_predictions_ds(predictions)\n",
    "\n",
    "from inr4ssh._src.operators import differential_simp as diffops_simp\n",
    "from inr4ssh._src.operators import differential as diffops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e050c0e-a4a7-4385-a9a0-69f76769223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pred = dm.create_predictions_ds(predictions)\n",
    "# ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f48174-8ece-40b2-a59d-a7b4766089db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41860c7-d962-4068-b62c-74404b92dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = trainer.test(learn, datamodule=dm)\n",
    "# t0 = time.time()\n",
    "predictions = trainer.predict(learn, datamodule=dm, return_predictions=True)\n",
    "predictions = torch.cat(predictions)\n",
    "\n",
    "ds_pred = dm.create_predictions_ds(predictions)\n",
    "\n",
    "from inr4ssh._src.operators import differential_simp as diffops_simp\n",
    "from inr4ssh._src.operators import differential as diffops\n",
    "\n",
    "learn.model.eval()\n",
    "coords, truths, preds, grads, qs = [], [], [], [], []\n",
    "for ix, iy in tqdm.tqdm(dm.predict_dataloader()):\n",
    "    with torch.set_grad_enabled(True):\n",
    "        # prediction\n",
    "        ix = torch.autograd.Variable(ix.clone(), requires_grad=True)\n",
    "        p_pred = learn.model(ix)\n",
    "\n",
    "        # p_pred = p_pred.clone()\n",
    "        # p_pred.require_grad_ = True\n",
    "\n",
    "        # gradient\n",
    "        p_grad = diffops_simp.gradient(p_pred, ix)\n",
    "        # p_grad = diffops.grad(p_pred, ix)\n",
    "        # q\n",
    "        q = diffops_simp.divergence(p_grad, ix)\n",
    "        # q = diffops.div(p_grad, ix)\n",
    "\n",
    "    # collect\n",
    "    truths.append(iy)\n",
    "    coords.append(ix)\n",
    "    preds.append(p_pred)\n",
    "    grads.append(p_grad)\n",
    "    qs.append(q)\n",
    "\n",
    "coords = torch.cat(coords).detach().numpy()\n",
    "preds = torch.cat(preds).detach().numpy()\n",
    "truths = torch.cat(truths).detach().numpy()\n",
    "grads = torch.cat(grads).detach().numpy()\n",
    "qs = torch.cat(qs).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07d577-c1dc-4e4a-bf74-3fcf4238671c",
   "metadata": {},
   "source": [
    "### Figure I: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371074d9-6e15-4cc8-9a34-d5df99116f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.thin(time=1).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=3,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c20d6-d0f9-413e-8d11-00f35fae2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f6335-81a6-4ceb-949b-2662225e8a7b",
   "metadata": {},
   "source": [
    "### Figure II: Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb20ec-9944-4fb2-b531-ebe0f1277dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.thin(time=1).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=3,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ef878-2f4f-4f9e-9249-049b5ac27a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887d598-dcc4-4691-a187-f8f334f120f8",
   "metadata": {},
   "source": [
    "### Figure III: Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5262c-2b6e-44e2-a5eb-a49d58ddcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_pred.true - ds_pred.pred).thin(time=1).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=3,\n",
    "    cmap=\"RdBu_r\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f73aa0-204b-40b3-9afc-c74803dff47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_pred.true - ds_pred.pred).hvplot.image(\n",
    "    x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6332052",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(y, x):\n",
    "    grad = gradient(y, x)\n",
    "    return divergence(grad, x)\n",
    "\n",
    "\n",
    "def divergence(y, x):\n",
    "    div = 0.0\n",
    "    for i in range(y.shape[-1]):\n",
    "        div += torch.autograd.grad(\n",
    "            y[..., i], x, torch.ones_like(y[..., i]), create_graph=True\n",
    "        )[0][..., i : i + 1]\n",
    "    return div\n",
    "\n",
    "\n",
    "def gradient(y, x, grad_outputs=None):\n",
    "    if grad_outputs is None:\n",
    "        grad_outputs = torch.ones_like(y)\n",
    "    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b91e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata = data.p.values[:nbmax, :ss, :ss].flatten()[:, None]\n",
    "# ydataT = torch.from_numpy(ydata)#.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c70ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.shape, ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseloss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def PINNloss(pred_p, lab, coords, w=1e-4):  # 1e-4\n",
    "    grad_nn = gradient(pred_p, coords)\n",
    "    q_nn = divergence(grad_nn, coords)\n",
    "    dlaplacU = gradient(q_nn, coords)\n",
    "    Jacob_U_laplacU = grad_nn[:, 1] * dlaplacU[:, 2] - grad_nn[:, 2] * dlaplacU[:, 1]\n",
    "    ###########\n",
    "    function_loss = mseloss(dlaplacU[:, 0] + Jacob_U_laplacU, torch.zeros(1).double())\n",
    "    data_loss = mseloss(pred_p, lab)\n",
    "    return data_loss + w * function_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(traindata))\n",
    "nbsample = np.int64(len(traindata) * 0.1)  # 1% of data\n",
    "nbsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528eb7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(traindata[perm, :][:nbsample, :], ydata[perm, :][:nbsample, :])),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "torch.manual_seed(2022)\n",
    "\n",
    "model = Siren(\n",
    "    in_features=3,\n",
    "    out_features=1,\n",
    "    hidden_features=64,\n",
    "    hidden_layers=3,\n",
    "    outermost_linear=True,\n",
    ").double()\n",
    "# model.load_state_dict(torch.load('/home/rlguensat/MLstuff/SIREN_addPhysLoss_SGD.h5'))#_finetune_addPhysLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, coords = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = PINNloss(outputs, labels, coords)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # epoch loss\n",
    "        epoch_loss += outputs.shape[0] * loss.item()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000  # print every 1000 mini-batch\n",
    "            print(\"  batch {} loss: {}\".format(i + 1, last_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb655a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_adam = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH {}:\".format(epoch + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    epoch_loss = train_one_epoch()\n",
    "    h_adam.append(epoch_loss)\n",
    "    print(\"EPOCH loss {}:\".format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507858db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16\n",
    "plt.semilogy(h_adam, label=\"Adam\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d89722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/home/rlguensat/MLstuff/SIREN_addPhysLoss_noweighting.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac2fd3",
   "metadata": {},
   "source": [
    "# Let us take the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ad719",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = torch.from_numpy(traindata[: ss * 256, :])\n",
    "point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a071b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8452172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_p, cc = model(point)\n",
    "grad_nn = gradient(pred_p, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_nn = divergence(grad_nn, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(pred_p.detach().numpy().reshape((256, ss)))\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(data.p[0, :256, :ss])\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(\n",
    "    pred_p.detach().numpy().reshape((256, ss)) - data.p[0, :256, :ss], cmap=\"coolwarm\"\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413143e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow((grad_nn[:, 1]).detach().numpy().reshape((256, ss)))\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(data.v[0, :256, :ss])\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(\n",
    "    (grad_nn[:, 1]).detach().numpy().reshape((256, ss)) - data.v[0, :256, :ss],\n",
    "    cmap=\"coolwarm\",\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow((q_nn[:, 0]).detach().numpy().reshape((256, ss)), vmin=-2, vmax=2)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(data.q[0, :256, :ss], vmin=-2, vmax=2)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(\n",
    "    (q_nn[:, 0]).detach().numpy().reshape((256, ss)) - data.q[0, :256, :ss],\n",
    "    cmap=\"coolwarm\",\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd813629",
   "metadata": {},
   "source": [
    "# Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f5a58",
   "metadata": {},
   "source": [
    "$$  \\partial_t q + \\boldsymbol{J}(p, q)= 0  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecf1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlaplacU = gradient(q_nn, cc)\n",
    "Jacob_U_laplacU = grad_nn[:, 1] * dlaplacU[:, 2] - grad_nn[:, 2] * dlaplacU[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((dlaplacU[:, 0] + Jacob_U_laplacU).detach().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea522d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_py39]",
   "language": "python",
   "name": "conda-env-torch_py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
