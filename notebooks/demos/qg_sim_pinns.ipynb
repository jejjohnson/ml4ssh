{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c00d4b7-e07e-4405-b643-c4db64f82510",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# QG Simulation\n",
    "\n",
    "* Fourier Feature Networks (FFN)\n",
    "* Siren\n",
    "* Modulated Siren (ModSiren)\n",
    "* Multiplicative Filter Networks (MFN)\n",
    "    * Fourier\n",
    "    * Gabor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2ee9e-04cc-4c5e-a3eb-4742a7ad7cd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".root\"])\n",
    "local = root.joinpath(\"experiments/qg\")\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))\n",
    "sys.path.append(str(local))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43eaf2f-23b0-4937-80a3-21938dc73ed2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any, cast\n",
    "import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import ReLU\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import os, imageio\n",
    "\n",
    "from inr4ssh._src.models.mlp import MLP\n",
    "from inr4ssh._src.models.activations import Swish\n",
    "from inr4ssh._src.datamodules.qg import QGSimulation\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from inr4ssh._src.models.image import ImageModel\n",
    "from inr4ssh._src.models.siren import Siren, SirenNet, Modulator, ModulatedSirenNet\n",
    "from inr4ssh._src.models.mfn import FourierNet, GaborNet\n",
    "from inr4ssh._src.models.activations import get_activation\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.argparse import add_argparse_args\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import hvplot.xarray\n",
    "\n",
    "pl.seed_everything(123)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc5b29-5204-4e91-acd9-ec85019cb687",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a180a4-628d-4bc4-affe-9bd58bb28b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from simple_parsing import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8578ca-f93e-4cdd-ba8e-292bb6e9d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize argparse\n",
    "parser = ArgumentParser()\n",
    "\n",
    "# add all experiment arguments\n",
    "parser.add_arguments(config.Logging, dest=\"logging\")\n",
    "parser.add_arguments(config.DataDir, dest=\"data\")\n",
    "parser.add_arguments(config.PreProcess, dest=\"preprocess\")\n",
    "parser.add_arguments(config.Features, dest=\"features\")\n",
    "parser.add_arguments(config.TrainTestSplit, dest=\"traintest\")\n",
    "parser.add_arguments(config.DataLoader, dest=\"dataloader\")\n",
    "parser.add_arguments(config.Model, dest=\"model\")\n",
    "parser.add_arguments(config.Siren, dest=\"siren\")\n",
    "parser.add_arguments(config.MLP, dest=\"mlp\")\n",
    "parser.add_arguments(config.FFN, dest=\"ffn\")\n",
    "parser.add_arguments(config.ModulatedSiren, dest=\"modsiren\")\n",
    "parser.add_arguments(config.MFN, dest=\"mfn\")\n",
    "parser.add_arguments(config.Losses, dest=\"losses\")\n",
    "parser.add_arguments(config.Optimizer, dest=\"optimizer\")\n",
    "parser.add_arguments(config.LRScheduler, dest=\"lr_scheduler\")\n",
    "parser.add_arguments(config.Callbacks, dest=\"callbacks\")\n",
    "# parser.add_arguments(config.EvalData, dest=\"eval\")\n",
    "# parser.add_arguments(config.Metrics, dest=\"metrics\")\n",
    "# parser.add_arguments(config.Viz, dest=\"viz\")\n",
    "\n",
    "# parse args\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e53dc-a678-4abe-922f-798d9c9021ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data.data_dir = f\"/Users/eman/.CMVolumes/cal1_data/qg_data/public/\"\n",
    "# args.data.data_dir = f\"/Volumes/EMANS_HDD/data/qg_sim/\"\n",
    "args.logging.log_dir = \"~/code_projects/logs/\"\n",
    "args.logging.mode = \"disabled\"\n",
    "\n",
    "args.preprocess.coarsen_Nx = 1\n",
    "args.preprocess.coarsen_Ny = 1\n",
    "args.preprocess.coarsen_time = 5\n",
    "\n",
    "args.traintest.noise = None\n",
    "\n",
    "args.traintest.step_Nx = 2\n",
    "args.traintest.step_Ny = 2\n",
    "args.traintest.step_time = 2\n",
    "args.traintest.missing_data = 0.9\n",
    "\n",
    "args.dataloader.batch_size = 4096  # 8192\n",
    "\n",
    "args.model = \"siren\"\n",
    "model_config = args.siren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d10c6-f915-4f3c-9ee2-a6b4d2fc769e",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c4179-3fae-4a30-978d-f0da657cd897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.io import simpleargs_2_ndict\n",
    "\n",
    "log_options = args.logging\n",
    "\n",
    "# params_dict = simpleargs_2_ndict(args)\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    config=args,\n",
    "    mode=log_options.mode,\n",
    "    project=log_options.project,\n",
    "    entity=log_options.entity,\n",
    "    dir=log_options.log_dir,\n",
    "    resume=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c836a-8790-4f6c-b5c2-4af553875648",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a614f-916d-4bc9-a93f-00f6d95b6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inr4ssh._src.data.qg import load_qg_data\n",
    "\n",
    "# ds = load_qg_data(dm.data.data_dir)\n",
    "\n",
    "# ds = ds.coarsen({\"time\": 2}, boundary=\"trim\", coord_func=\"mean\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855355e-1c69-41cc-b0c5-c6b07602f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = QGSimulation(\n",
    "    data=args.data,\n",
    "    preprocess=args.preprocess,\n",
    "    traintest=args.traintest,\n",
    "    features=args.features,\n",
    "    dataloader=args.dataloader,\n",
    "    # eval=args.eval\n",
    ")\n",
    "\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8fe535-71e6-4f1f-9d54-688177da26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm.ds_train), len(dm.ds_valid), len(dm.ds_test), len(dm.ds_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3834af2-1b4d-4938-9262-f9128bd8e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def array_2_da(coords, data, name=\"full_pred\", coords_name: List[str]=[\"x\", \"y\", \"t\"]):\n",
    "#     return pd.DataFrame(np.hstack([coords, data]), columns=[coords_name]+[name]).set_index(\n",
    "#         coords_name).to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da42420-5107-4cb3-9299-883a40ac4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = dm.create_xr_dataset(\"predict\")\n",
    "xr_data = xr.merge([xr_data, dm.create_xr_dataset(\"train\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6cdde-2843-44c4-8354-735f3a455352",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.train.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf9c29-368d-431b-b4b5-3bf1802d71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr_data.predict.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86ed21-0ae8-4682-ad36-38da4d2db3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.obs.thin(time=2).plot.imshow(\n",
    "#     col=\"time\", robust=True, col_wrap=4, cmap=\"viridis\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a850a1a-760a-45c0-9edb-7380fe7dbe87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The input data is a coordinate vector, $\\mathbf{x}_\\phi$, of the image coordinates.\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_\\phi \\in \\mathbb{R}^{D_\\phi}\n",
    "$$\n",
    "\n",
    "where $D_\\phi = [\\text{x}, \\text{y}]$. So we are interested in learning a function, $\\boldsymbol{f}$, such that we can input a coordinate vector and output a scaler/vector value of the pixel value.\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\boldsymbol{f}(\\mathbf{x}_\\phi; \\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc0de5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Module\n",
    "\n",
    "\n",
    "#### Train-Test Split\n",
    "\n",
    "In this example, we are only taking every other pixel for training and validation. It is a very simple and well-defined problem which each of the neural networks should be able to solve. The final test image is the original full resolution image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c54fc3-f3b5-45f4-b68f-15192bbfc605",
   "metadata": {},
   "source": [
    "Notice how we have `131_072` points from training and validation and `262_144` for the testing. This is because we have *raveled* the image where each coordinate is a vector of `x,y`. So these are a lot of points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fcb801-d1e5-4f3b-88a1-ec4580b29162",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "init = dm.ds_train[:32]\n",
    "x_init, y_init = init\n",
    "x_init.shape, y_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18098026-febf-44a1-91cf-5a34e2417a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init.min(), x_init.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b934c-ab01-4818-8ecb-cbfab71a9192",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "For this, we will use a simple adam optimizer with a `learning_rate` of 1e-4. From many studies, it appears that a lower learning rate works well with this methods because there is a lot of data. In addition, a bigger `batch_size` is also desireable. We will set the `num_epochs` to `1_000` which should be good enough for a single image. Obviously more epochs and a better learning rate scheduler would result in better results but this will be sufficient for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2b217-a6b4-4210-97b5-2f00a0cefc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "warmup = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9b10d-159a-4d90-9a3d-a893a5b7d87d",
   "metadata": {},
   "source": [
    "### Scheduler\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<figcaption align = \"center\">\n",
    "  <b>Fig.1 - An example for learning rate reduction when the validation loss stagnates. Source: \n",
    "    <a href=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\">Blog</a>\n",
    "  </b>\n",
    "  </figcaption>\n",
    "</p>\n",
    "\n",
    "We will use a simple learning rate scheduler - `reduce_lr_on_plateau`. This will automatically reduce the learning rate as the validation loss stagnates. It will ensure that we really squeeze out as much performance as possible from our models during the training procedure.We start with a (relatively) high `learning_rate` of `1e-4` so we will set the `patience` to 5 epochs. So if there is no change in with every epoch, we decrease the learning rate by a factor of `0.1`.\n",
    "\n",
    "This is a rather crude (but effective) method but it tends to work well in some situations. A better method might be the `cosine_annealing` method or the `exponential_decay` method. See other [examples](https://www.kaggle.com/code/snnclsr/learning-rate-schedulers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7a402-e645-4c97-81ac-c8658a8a56f9",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "We are going with a very simple `loss` function: the *mean squared error* (MSE). This is given by:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\theta}) = \\frac{1}{N} \\sum_n^N \\left( \\mathbf{y}_n - \\boldsymbol{f}_{\\boldsymbol{\\theta}}(\\mathbf{x}_n) \\right)^2\n",
    "$$\n",
    "\n",
    "We won't code this from scratch, we will just use the PyTorch function, `nn.MSELoss`, and we will use the `mean` reduction parameter.\n",
    "\n",
    "\n",
    "### PSNR\n",
    "\n",
    "We will also keep track of the signal to noise ratio (PSNR) which will give us an indication of how well we are learning.\n",
    "\n",
    "$$\n",
    "\\text{PSNR}(\\mathbf{x}) = - 10 \\log (2 * \\text{MSE}(\\mathbf{x}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9971a-8108-4e2e-ae58-5e412c6c27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59edd76-49b2-4753-bdf7-b0d2072b810b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc78bc6-8540-44d1-8ec2-3e08c8ad1ef6",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1e241-c529-49c8-a832-0760f9847d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps_per_epoch = len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704a935-9d80-4476-95db-60a34b3202ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from inr4ssh._src.losses.qg import qg_loss\n",
    "from inr4ssh._src.operators.differential_simp import gradient\n",
    "from inr4ssh._src.operators.differential import grad as grad_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bebfb9-2b68-400c-8af9-5f2d83cd6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer: str = \"adam\",\n",
    "        qg: bool = True,\n",
    "        alpha: float = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.hyperparams = cast(Dict[str, Any], self.hparams)\n",
    "        self.loss = nn.MSELoss(reduction=\"mean\")\n",
    "        # self.reg = QGRegularization()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _qg_loss(self, x):\n",
    "        with torch.set_grad_enabled(True):\n",
    "\n",
    "            f = self.hyperparams.get(\"f\", 0.0001)\n",
    "            g = self.hyperparams.get(\"g\", 9.81)\n",
    "\n",
    "            x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            out = self.model(x_var)\n",
    "            out *= f / g\n",
    "            loss = qg_loss(\n",
    "                out,\n",
    "                x_var,\n",
    "                f=f,\n",
    "                g=g,\n",
    "                Lr=self.hyperparams.get(\"Lr\", 1.0),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # output\n",
    "        x, y = batch\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        # loss function\n",
    "        loss_data = self.loss(y, pred)\n",
    "\n",
    "        if self.hyperparams.get(\"qg\", False):\n",
    "            # x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            # out = self.forward(x_var)\n",
    "            # reg = qg_loss(out, x_var, 1.0, 1.0, 1.0, \"mean\")\n",
    "            reg = self._qg_loss(x)\n",
    "\n",
    "            loss = loss_data + self.hyperparams.get(\"alpha\", 0.2) * reg\n",
    "\n",
    "            self.log(\"train_reg\", reg, prog_bar=True)\n",
    "            self.log(\"train_data\", loss_data, prog_bar=True)\n",
    "        else:\n",
    "            loss = loss_data\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # output\n",
    "        x, y = batch\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        # loss function\n",
    "        loss_data = self.loss(y, pred)\n",
    "\n",
    "        if self.hyperparams.get(\"qg\", False):\n",
    "            # x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            # out = self.forward(x_var)\n",
    "            # reg = qg_loss(out, x_var, 1.0, 1.0, 1.0, \"mean\")\n",
    "            reg = self._qg_loss(x)\n",
    "\n",
    "            loss = loss_data + self.hyperparams.get(\"alpha\", 0.2) * reg\n",
    "\n",
    "            self.log(\"val_reg\", reg, prog_bar=True)\n",
    "            self.log(\"val_data\", loss_data, prog_bar=True)\n",
    "        else:\n",
    "            loss = loss_data\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # output\n",
    "        x, y = batch\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        # loss function\n",
    "        loss_data = self.loss(y, pred)\n",
    "\n",
    "        if self.hyperparams.get(\"qg\", False):\n",
    "            # x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "            # out = self.forward(x_var)\n",
    "            # reg = qg_loss(out, x_var, 1.0, 1.0, 1.0, \"mean\")\n",
    "            reg = self._qg_loss(x)\n",
    "\n",
    "            loss = loss_data + self.hyperparams.get(\"alpha\", 0.2) * reg\n",
    "\n",
    "            self.log(\"test_reg\", reg, prog_bar=True)\n",
    "            self.log(\"test_data\", loss_data, prog_bar=True)\n",
    "        else:\n",
    "            loss = loss_data\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # output\n",
    "        x, y = batch\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # configure optimizer\n",
    "        if self.hyperparams.optimizer == \"adam\":\n",
    "            optimizer = Adam(\n",
    "                self.model.parameters(), lr=self.hyperparams.get(\"lr\", 1e-4)\n",
    "            )\n",
    "        elif self.hyperparams.optimizer == \"lbfgs\":\n",
    "            optimizer = Adam(\n",
    "                self.model.parameters(), lr=self.hyperparams.get(\"lr\", 1e-4)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized optimizer: {optimizer}\")\n",
    "\n",
    "        # configure lr scheduler\n",
    "        # scheduler = ReduceLROnPlateau(\n",
    "        #     optimizer, patience=self.hyperparams.get(\"lr_schedule_patience\", 5)\n",
    "        # )\n",
    "        # scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        #     optimizer,\n",
    "        #     max_lr=self.hyperparams.get(\"lr\", 1e-4),\n",
    "        #     steps_per_epoch=num_steps_per_epoch,\n",
    "        #     epochs=num_epochs,\n",
    "        # )\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        #     optimizer, T_max=num_epochs, eta_min=0\n",
    "        # )\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer,\n",
    "            warmup_epochs=self.hyperparams.get(\"warmup\", 10),\n",
    "            max_epochs=self.hyperparams.get(\"num_epochs\", 100),\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220c818-62ab-45fa-b104-914eb6a47f5e",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ca869-16be-426e-a358-a05c0208209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [TQDMProgressBar(refresh_rate=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025da5c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "* Fourier Feature Networks (FFN)\n",
    "* Siren\n",
    "* Modulated Siren (ModSiren)\n",
    "* Multiplicative Filter Networks (MFN)\n",
    "    * Fourier\n",
    "    * Gabor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106a352-bcbc-41f9-9f0a-31ec78de0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.models.models_factory import model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbeacf-623e-4e7f-a781-fd24e59acb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = x_init.shape[1]\n",
    "dim_out = y_init.shape[1]\n",
    "\n",
    "\n",
    "# args.ffn.encoder = \"positional\"\n",
    "net = model_factory(args.model, dim_in, dim_out, model_config)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fac68-f6af-4c25-8caa-2c9ce0a2557f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dim_in = x_init.shape[1]\n",
    "# dim_hidden = 256\n",
    "# dim_out = y_init.shape[1]\n",
    "# num_layers = 5\n",
    "# activation = \"swish\"  # Swish()  # nn.ReLU()#\n",
    "# final_activation = \"identity\"\n",
    "\n",
    "# mlp_net = MLP(\n",
    "#     dim_in=dim_in,\n",
    "#     dim_hidden=dim_hidden,\n",
    "#     dim_out=dim_out,\n",
    "#     num_layers=num_layers,\n",
    "#     activation=get_activation(activation),\n",
    "#     final_activation=get_activation(final_activation),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88b6fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learn = ImageModel(\n",
    "    net,\n",
    "    learning_rate=learning_rate,\n",
    "    warmup=warmup,\n",
    "    num_epochs=num_epochs,\n",
    "    alpha=0.0,\n",
    "    Lr=1.0,\n",
    "    f=1.0,\n",
    "    g=1.0,\n",
    "    qg=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb96b4-6d83-47f0-92b7-42337db88522",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = learn.forward(x_init)\n",
    "\n",
    "# assert out.shape[0] == x_init.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e506e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    min_epochs=1,\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=\"mps\",\n",
    "    # devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    # gradient_clip_val=1.0,\n",
    "    # gradient_clip_algorithm=\"norm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27eb75f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    learn,\n",
    "    datamodule=dm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecaf881",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = trainer.test(learn, dataloaders=dm.test_dataloader())\n",
    "\n",
    "results[\"data\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a0da9-8545-4329-ad65-d1071685fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\n",
    "        key,\n",
    "        f\"{results[key][0]['test_loss']:4.4f}\",\n",
    "        # \"{:,}\".format(sum([np.prod(p.shape) for p in flow_dict[key][\"model\"].parameters()]))\n",
    "    ]\n",
    "    for key in results\n",
    "]\n",
    "display(\n",
    "    HTML(\n",
    "        tabulate.tabulate(\n",
    "            table,\n",
    "            tablefmt=\"html\",\n",
    "            headers=[\n",
    "                \"Model\",\n",
    "                \"MSE\",  # \"Num Parameters\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ded860",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "predictions = trainer.predict(learn, dataloaders=dm, return_predictions=True)\n",
    "predictions = torch.cat(predictions)\n",
    "# t1 = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151339ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds_pred = dm.create_predictions_ds(predictions)\n",
    "ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b8831-25b5-4680-b32c-abbb72d5968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.thin(time=2).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=4,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911f61a-ec94-4c0e-9d14-3b06e0df6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.thin(time=2).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=4,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf951d-773e-457c-9427-3560a7af00cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc93018-02df-4135-88a1-aee4214ef672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pred.pred.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf745c5c-9649-4a4d-8b15-b5f87a6deb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pred.true.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb4e66-fa4c-45a7-979b-c323b385a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inr4ssh._src.operators.differential import grad, laplacian, jac\n",
    "# from torch.autograd import functional as f_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b6d5e-b4bf-4a14-8d02-b0a0cb3e2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gradient once\n",
    "# with torch.enable_grad():\n",
    "#     x = dm.ds_train[:32][0]\n",
    "#     x_var = torch.autograd.Variable(x.clone(), requires_grad=True)\n",
    "#     u = learn.model(x_var)\n",
    "\n",
    "#     x_var_space = x_var[:, :2].clone()\n",
    "#     x_var_space = torch.autograd.Variable(x_var_space, requires_grad=True)\n",
    "#     u_lap = laplacian(u, x_var_space)\n",
    "\n",
    "#     # jacobian\n",
    "#     u_jac = grad(u, x_var)\n",
    "\n",
    "#     # laplacian\n",
    "#     x_var_space = x_var[:, :2].clone()\n",
    "#     x_var_space = torch.autograd.Variable(x_var_space, requires_grad=True)\n",
    "#     u_lap = laplacian(u, x_var_space)\n",
    "\n",
    "#     # gradient o laplacian\n",
    "#     u_lap_jac = grad(u_lap, x_var)\n",
    "#     assert u_jac.shape == x_var.shape\n",
    "#     assert u_lap.shape == u.shape\n",
    "#     assert u_lap_jac.shape == x_var.shape\n",
    "\n",
    "#     loss = u_lap\n",
    "\n",
    "#     loss = loss.square().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7198a3-fdf1-4638-8c56-072aa7100c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be096f-479d-474c-a361-b6f249e2a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(x):\n",
    "#     return learn.model(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d08c5e-484c-4083-b0da-b100e15b8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_grad_ = f_grad.jacobian(f, x_var)\n",
    "\n",
    "# torch.testing.assert_close(u_grad, u_grad_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db633e-2d59-4063-81ea-5a4614c61c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = qg_loss(out, x_var, reduction=\"mean\")\n",
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2ea21-fc51-4734-b006-5e8086618a2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## QG Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5c876-d2fe-4286-bc79-91f95f7b8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1_000\n",
    "learning_rate = 1e-4\n",
    "warmup = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d07e69-974e-449b-841e-f213e9a8c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModelQG(ImageModel):\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # configure optimizer\n",
    "        if self.hyperparams.optimizer == \"adam\":\n",
    "            optimizer = Adam(\n",
    "                self.model.parameters(), lr=self.hyperparams.get(\"lr\", 1e-4)\n",
    "            )\n",
    "        elif self.hyperparams.optimizer == \"lbfgs\":\n",
    "            optimizer = Adam(\n",
    "                self.model.parameters(), lr=self.hyperparams.get(\"lr\", 1e-4)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized optimizer: {optimizer}\")\n",
    "\n",
    "        # configure lr scheduler\n",
    "        # scheduler = ReduceLROnPlateau(\n",
    "        #     optimizer, patience=self.hyperparams.get(\"lr_schedule_patience\", 5)\n",
    "        # )\n",
    "        # scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        #     optimizer,\n",
    "        #     max_lr=self.hyperparams.get(\"lr\", 1e-4),\n",
    "        #     steps_per_epoch=num_steps_per_epoch,\n",
    "        #     epochs=num_epochs,\n",
    "        # )\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        #     optimizer, T_max=num_epochs, eta_min=0\n",
    "        # )\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer,\n",
    "            warmup_epochs=self.hyperparams.get(\"warmup\", 10),\n",
    "            max_epochs=self.hyperparams.get(\"num_epochs\", 100),\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a54562-a82b-4590-8626-8d885a36d1a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learn_pinns = ImageModelQG(\n",
    "    learn.model,\n",
    "    learning_rate=learning_rate,\n",
    "    alpha=0.1,\n",
    "    qg=True,\n",
    "    num_epochs=num_epochs,\n",
    "    warmup=warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bbde5-9e2e-41ba-9b45-19d8de130519",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = learn_pinns.forward(x_init)\n",
    "\n",
    "# assert out.shape[0] == x_init.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49038b-7bf7-4aa2-9c87-090a3367c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    min_epochs=1,\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=\"mps\",\n",
    "    # devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    # gradient_clip_val=1.0,\n",
    "    # gradient_clip_algorithm=\"norm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f8bc7-01cd-495b-b779-c3a3a900a16e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    learn_pinns,\n",
    "    datamodule=dm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03202b2e-0519-452b-abe0-c8d0f899c5d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = trainer.test(learn_pinns, dataloaders=dm.test_dataloader())\n",
    "\n",
    "results[\"qg\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567064a-474e-4124-a332-d8fd2f42298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\n",
    "        key,\n",
    "        f\"{results[key][0]['test_loss']:4.4f}\",\n",
    "        # f\"{results[key][0]['test_reg']:4.4f}\",\n",
    "        # f\"{results[key][0]['test_data']:4.4f}\",\n",
    "        # \"{:,}\".format(sum([np.prod(p.shape) for p in flow_dict[key][\"model\"].parameters()]))\n",
    "    ]\n",
    "    for key in results\n",
    "]\n",
    "display(\n",
    "    HTML(\n",
    "        tabulate.tabulate(\n",
    "            table,\n",
    "            tablefmt=\"html\",\n",
    "            headers=[\n",
    "                \"Model\",\n",
    "                \"Loss\",  # \"Num Parameters\"\n",
    "                # \"Reg\",\n",
    "                # \"MSE\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7887e9-5411-4be8-bc7f-1040d1118b87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "predictions = trainer.predict(learn, dataloaders=dm, return_predictions=True)\n",
    "predictions = torch.cat(predictions)\n",
    "# t1 = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ba2ca-5725-4a5b-ac7c-54b1c21cce27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds_pred = dm.create_predictions_ds(predictions)\n",
    "ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abda12-dc9e-477a-afc3-461ab30cfb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.thin(time=2).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=4,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916d92a-119c-40b7-92f2-cb59bb7af1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.thin(time=2).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=4,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb1bae-cae7-4611-8e8e-f539e635bf03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a32f7b-fff0-458e-afac-c8670ca0e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d9933-9eed-4445-8468-c75319fe206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eadd23-4494-41b8-861e-028675419240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f67e2-b193-42b8-b516-17e7a4f4c765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d285137-8ea7-467c-a419-284a8b4cf90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06928a-e93c-4d88-a1fe-9ad36bbe3a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d5dda-0ad3-4efb-aa72-8e7ec82d218e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d035c-917f-40e4-8513-402918a2f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init.min(dim=0), x_init.max(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581408d-9573-42e4-97c2-514d5448ba91",
   "metadata": {},
   "source": [
    "```python\n",
    "coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "SSH = self.firstnet(coords)\n",
    "gradSSH = self.gradient(SSH, coords)\n",
    "dSSHdx = gradSSH[:,0:1]\n",
    "dSSHdy = gradSSH[:,1:2]\n",
    "d2SHHd2x = self.gradient(dSSHdx, coords)[:,0:1]\n",
    "d2SHHd2y = self.gradient(dSSHdy, coords)[:,1:2]\n",
    "dQ = self.gradient(d2SHHd2x+d2SHHd2y, coords)\n",
    "output = self.secondnet(self.Bnorm(torch.cat((dSSHdy,\n",
    "                                              dSSHdx,\n",
    "                                              d2SHHd2x+d2SHHd2y,\n",
    "                                              dQ[:,0:1],\n",
    "                                              dQ[:,1:2]),1)))\n",
    "                                              #dQ[:,0:1] * dSSHdy,\n",
    "                                              #dQ[:,1:2] * dSSHdx\n",
    "output =  dSSHdx *  dQ[:,1:2] -   dSSHdy * dQ[:,0:1]\n",
    "return (1e-5*dQ[:,2:3]-output), coords, SSH\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3665a-c5a6-4907-b375-9417c43a3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable [Nx, Ny, T]\n",
    "x_var = torch.autograd.Variable(x_init[:5], requires_grad=True)\n",
    "# ssh\n",
    "ssh = learn.model(x_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a46f4-31e3-4cd1-90a4-08f4581b625e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{J} = \\boldsymbol{J}(\\mathbf{X})\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $\\mathbf{X} \\in \\mathbb{R}^{N \\times D_\\phi}$\n",
    "* $\\boldsymbol{J}: \\mathbb{R}^{N \\times D_\\phi} \\rightarrow \\mathbb{R}^{N \\times D_\\phi}$\n",
    "* $\\mathbf{J} \\in \\mathbb{R}^{N \\times D_\\phi}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f844fd6-337a-4877-8b07-2332e6d665e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGRegularization(nn.Module):\n",
    "    def __init__(\n",
    "        self, f: float = 1.0, g: float = 1.0, Lr: float = 1.0, reduction: str = \"mean\"\n",
    "    ):\n",
    "        super(QGRegularization).__init__()\n",
    "\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "        self.Lr = Lr\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def __call__(self, out, x):\n",
    "\n",
    "        x = x.requires_grad_(True)\n",
    "\n",
    "        # gradient, nabla x\n",
    "        out_jac = diffops_simp.gradient(out, x)\n",
    "        assert ssh_jac.shape == x.shape\n",
    "\n",
    "        # calculate term 1\n",
    "        loss1 = _qg_term1(out_jac, x, self.f, self.g, self.Lr)\n",
    "        # calculate term 2\n",
    "        loss2 = _qg_term2(out_jac, self.f, self.g, self.Lr)\n",
    "\n",
    "        loss = loss_1 - loss_2\n",
    "\n",
    "        if self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        elif self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized reduction: {self.reduction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5cef30-2ed7-4afb-81e3-e9cea3fdb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qg_constants(f, g, L_r):\n",
    "    c_1 = f / g\n",
    "    c_2 = 1 / L_r**2\n",
    "    c_3 = c_1 * c_2\n",
    "    return c_1, c_2, c_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fe2e2-e381-41cb-88c6-2b6c5743bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _qg_term1(ssh_grad, x_var, f: float = 1.0, g: float = 1.0, L_r: float = 1.0):\n",
    "    \"\"\"\n",
    "    t1 = ∂𝑡∇2𝑢 + 𝑐1 ∂𝑥𝑢 ∂𝑦∇2𝑢 − 𝑐1 ∂𝑦𝑢 ∂𝑥∇2𝑢\n",
    "    Parameters:\n",
    "    ----------\n",
    "    ssh_grad: torch.Tensor, (B, Nx, Ny, T)\n",
    "    x_var: torch.Tensor, (B,\n",
    "    f: float, (,)\n",
    "    g: float, (,)\n",
    "    Lr: float, (,)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    loss : torch.Tensor, (B,)\n",
    "    \"\"\"\n",
    "\n",
    "    x_var = x_var.requires_grad_(True)\n",
    "    c_1, c_2, c_3 = qg_constants(f, g, L_r)\n",
    "    # jacobian^2 x2, ∇2\n",
    "    ssh_grad2 = diffops_simp.gradient(ssh_grad, x_var)\n",
    "    assert ssh_grad2.shape == x_var.shape\n",
    "\n",
    "    # split jacobian -> partial x, partial y, partial t\n",
    "    ssh_grad2_x, ssh_grad2_y, ssh_grad2_t = torch.split(ssh_grad2, [1, 1, 1], dim=1)\n",
    "    assert ssh_grad_x.shape == ssh_grad_y.shape == ssh_grad_t.shape\n",
    "\n",
    "    # laplacian (spatial), nabla^2\n",
    "    ssh_lap = ssh_grad2_x + ssh_grad2_y\n",
    "    assert ssh_lap.shape == ssh_grad_x.shape == ssh_grad_y.shape\n",
    "\n",
    "    # gradient of laplacian, ∇ ∇2\n",
    "    ssh_grad_lap = diffops_simp.gradient(ssh_lap, x_var)\n",
    "    assert ssh_grad_lap.shape == x_var.shape\n",
    "\n",
    "    # split laplacian into partials\n",
    "    ssh_grad_lap_x, ssh_grad_lap_y, ssh_grad_lap_t = torch.split(\n",
    "        ssh_grad_lap, [1, 1, 1], dim=1\n",
    "    )\n",
    "    assert ssh_grad_lap_x.shape == ssh_grad_lap_y.shape == ssh_grad_lap_t.shape\n",
    "\n",
    "    # term 1\n",
    "    loss = (\n",
    "        ssh_grad_lap_t\n",
    "        + c_1 * ssh_grad_x * ssh_grad_lap_y\n",
    "        - c_1 * ssh_grad_y * ssh_grad_lap_x\n",
    "    )\n",
    "    assert (\n",
    "        loss.shape\n",
    "        == ssh_grad_lap_t.shape\n",
    "        == ssh_grad_lap_y.shape\n",
    "        == ssh_grad_lap_x.shape\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def _qg_term2(ssh_grad, f: float = 1.0, g: float = 1.0, Lr: float = 1.0):\n",
    "\n",
    "    \"\"\"\n",
    "    t2 = 𝑐2 ∂𝑡(𝑢) + 𝑐3 ∂𝑥(𝑢) ∂𝑦(𝑢) − 𝑐3 ∂𝑦(𝑢) ∂𝑥(𝑢)\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    ssh_grad: torch.Tensor, (B, Nx, Ny, T)\n",
    "    f: float, (,)\n",
    "    g: float, (,)\n",
    "    Lr: float, (,)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    loss : torch.Tensor, (B,)\n",
    "    \"\"\"\n",
    "    _, c_2, c_3 = qg_constants(f, g, Lr)\n",
    "\n",
    "    # get partial derivatives | partial x, y, t\n",
    "    ssh_grad_x, ssh_grad_y, ssh_grad_t = torch.split(ssh_jac, [1, 1, 1], dim=1)\n",
    "\n",
    "    # calculate term 2\n",
    "    loss = (\n",
    "        c_2 * ssh_grad_t + c_3 * ssh_grad_x * ssh_grad_y - c_3 * ssh_grad_y * ssh_grad_x\n",
    "    )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e7ade-6d9b-4faf-b926-9abbab0fd63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qg_loss(ssh, x, f, g, Lr):\n",
    "\n",
    "    # gradient, nabla x\n",
    "    ssh_jac = diffops_simp.gradient(ssh, x)\n",
    "    assert ssh_jac.shape == x.shape\n",
    "\n",
    "    # calculate term 1\n",
    "    loss1 = _qg_term1(ssh_jac, x, f, g, Lr)\n",
    "    # calculate term 2\n",
    "    loss2 = _qg_term2(ssh_jac, f, g, Lr)\n",
    "\n",
    "    return loss1 - loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f26ab-bb0e-4022-b125-a53da245f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable [Nx, Ny, T]\n",
    "x_var = torch.autograd.Variable(x_init[:5], requires_grad=True)\n",
    "# ssh\n",
    "ssh = learn.model(x_var)\n",
    "\n",
    "qg_reg = QGRegularization(f=1.0, g=1.0, Lr=1.0)\n",
    "\n",
    "loss = qg_reg(ssh, x_var)\n",
    "assert loss.shape[0] == x_var.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1fcc0-a637-4a7f-9bdc-e680258b9a27",
   "metadata": {},
   "source": [
    "**Term II** ($\\nabla$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365f2c5-30d9-4905-9e7d-e882a8ed334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get partial derivatives | partial x, y, t\n",
    "ssh_grad_x, ssh_grad_y, ssh_grad_t = torch.split(ssh_jac, [1, 1, 1], dim=1)\n",
    "\n",
    "assert ssh_grad_x.shape == ssh_grad_y.shape == ssh_grad_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80d0d6-228a-49ed-b8b3-28d6c67dc9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1.1\n",
    "g = 1.0\n",
    "c_1 = f / g\n",
    "\n",
    "constant_lr2 = 1.1\n",
    "c_2 = 1 / constant_lr2\n",
    "\n",
    "c_3 = c_1 * c_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295c56f-2f24-4e0b-a5f7-eff023da1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate term 2\n",
    "t2 = c_2 * ssh_grad_t + c_3 * ssh_grad_x * ssh_grad_y - c_3 * ssh_grad_y * ssh_grad_x\n",
    "\n",
    "assert t2.shape == ssh_grad_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d53c782-cc1f-40f7-bffe-a61b08b0964c",
   "metadata": {},
   "source": [
    "### Term I ($\\nabla \\cdot \\nabla^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49eb60-f1b0-45f0-84af-dccc56d72d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _qg_term1(ssh_grad, x_var, f, g, L_r):\n",
    "    \"\"\"\n",
    "    t1 = ∂𝑡∇2𝑢 + 𝑐1 ∂𝑥𝑢 ∂𝑦∇2𝑢 − 𝑐1 ∂𝑦𝑢 ∂𝑥∇2𝑢\n",
    "    \"\"\"\n",
    "    c_1, c_2, c_3 = qg_constants(f, g, L_r)\n",
    "    # jacobian^2 x2, ∇2\n",
    "    ssh_grad2 = diffops_simp.gradient(ssh_grad, x_var)\n",
    "    assert ssh_hessian.shape == x_var.shape\n",
    "\n",
    "    # split jacobian -> partial x, partial y, partial t\n",
    "    ssh_grad2_x, ssh_grad2_y, ssh_grad2_t = torch.split(ssh_grad2, [1, 1, 1], dim=1)\n",
    "    assert ssh_grad_x.shape == ssh_grad_y.shape == ssh_grad_t.shape\n",
    "\n",
    "    # laplacian (spatial), nabla^2\n",
    "    ssh_lap = ssh_grad2_x + ssh_grad2_y\n",
    "    assert ssh_lap.shape == ssh_grad_x.shape == ssh_grad_y.shape\n",
    "\n",
    "    # gradient of laplacian, ∇ ∇2\n",
    "    ssh_grad_lap = diffops_simp.gradient(ssh_lap, x_var)\n",
    "    assert ssh_grad_lap.shape == x_var.shape\n",
    "\n",
    "    # split laplacian into partials\n",
    "    ssh_grad_lap_x, ssh_grad_lap_y, ssh_grad_lap_t = torch.split(\n",
    "        ssh_grad_lap, [1, 1, 1], dim=1\n",
    "    )\n",
    "    assert ssh_grad_lap_x.shape == ssh_grad_lap_y.shape == ssh_grad_lap_t.shape\n",
    "\n",
    "    # term 1\n",
    "    t1 = (\n",
    "        ssh_grad_lap_t\n",
    "        + c_1 * ssh_grad_x * ssh_grad_lap_y\n",
    "        - c_1 * ssh_grad_y * ssh_grad_lap_x\n",
    "    )\n",
    "    assert t1.shape == ssh_grad_lap_t.shape\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e6a5d-03fd-435f-96b4-91ddb179a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient x2, ∇2\n",
    "ssh_grad2 = diffops_simp.gradient(ssh_grad, x_var)\n",
    "assert ssh_hessian.shape == x_var.shape\n",
    "\n",
    "ssh_grad2_x, ssh_grad2_y, ssh_grad2_t = torch.split(ssh_grad2, [1, 1, 1], dim=1)\n",
    "assert ssh_grad_x.shape == ssh_grad_y.shape == ssh_grad_t.shape\n",
    "\n",
    "# laplacian\n",
    "ssh_lap = ssh_grad2_x + ssh_grad2_y\n",
    "assert ssh_lap.shape == ssh_grad_x.shape\n",
    "\n",
    "# gradient of laplacian, ∇ ∇2\n",
    "ssh_grad_lap = diffops_simp.gradient(ssh_lap, x_var)\n",
    "assert ssh_grad_lap.shape == x_var.shape\n",
    "\n",
    "ssh_grad_lap_x, ssh_grad_lap_y, ssh_grad_lap_t = torch.split(\n",
    "    ssh_grad_lap, [1, 1, 1], dim=1\n",
    ")\n",
    "assert ssh_grad_lap_x.shape == ssh_grad_lap_y.shape == ssh_grad_lap_t.shape\n",
    "\n",
    "# term 1\n",
    "t1 = (\n",
    "    ssh_grad_lap_t\n",
    "    + c_1 * ssh_grad_x * ssh_grad_lap_y\n",
    "    - c_1 * ssh_grad_y * ssh_grad_lap_x\n",
    ")\n",
    "assert t1.shape == ssh_grad_lap_t.shape\n",
    "\n",
    "t1_ = (\n",
    "    ssh_grad_lap[:, -1:]\n",
    "    + c_1 * ssh_grad_x * ssh_grad_lap[:, 1:2]\n",
    "    - c_1 * ssh_grad_y * ssh_grad_lap[:, 0:1]\n",
    ")\n",
    "assert t1.shape == ssh_grad_lap_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b53921-4f77-4c8a-b931-197a52900ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501824fa-0239-434c-bd03-15f3be6019ab",
   "metadata": {},
   "source": [
    "$$\n",
    "\\partial_t \\nabla^2 u + c_1 \\partial_x u \\partial_y \\nabla^2 u -  c_1 \\partial_y u \\partial_x \\nabla^2u\n",
    "$$\n",
    "\n",
    "---\n",
    "$$\n",
    "\\underbrace{\\partial_t \\nabla^2 u + c_1 \\partial_x u \\partial_y \\nabla^2 u -  c_1 \\partial_y u \\partial_x \\nabla^2u}_{\\nabla^2} +  \\underbrace{c_2 \\partial_t u + c_3 \\partial_x u \\partial_y u - c_3\\partial_y u \\partial_x u}_{\\nabla} = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "**Gradient** (order 1)\n",
    "\n",
    "$$\n",
    "\\nabla u = \n",
    "\\begin{bmatrix}\n",
    "\\nabla_t u \\\\ \\nabla_x u \\\\ \\nabla_y u\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "**Gradient** (order 3)\n",
    "\n",
    "$$\n",
    "\\nabla^3 u = \n",
    "\\begin{bmatrix}\n",
    "\\nabla^3_t u \\\\ \\nabla^3_x u \\\\ \\nabla^3_y u\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\nabla \\cdot \\nabla^2 u = \n",
    "\\begin{bmatrix} \n",
    "\\nabla_t & \\nabla_x & \\nabla_y\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ c_1 \\\\ -c_1\n",
    "\\end{bmatrix}\n",
    "\\circ\n",
    "\\begin{bmatrix}\n",
    "\\nabla^2_t u \\\\ \\nabla^2_x u \\\\ \\nabla^2_y u\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174cb07-c7f0-4098-a99d-c41221b59d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b19ba-cfd3-4cf8-9ab9-f24c0d45ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b8ad8-9ddf-4988-81b3-530ec95bf2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbf00c-f5cd-4cb1-8461-96c3dd48e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc461e-91c9-4ca5-9c8d-e42917b66cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70d2e25024e70c662658c456d9e0a340af3759493bed99b867179c40cf269d86"
  },
  "kernelspec": {
   "display_name": "Python [conda env:torch_py39]",
   "language": "python",
   "name": "conda-env-torch_py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
