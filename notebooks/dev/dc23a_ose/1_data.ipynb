{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSSE 2023a - Global Altimetry Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".root\"])\n",
    "\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "\n",
    "from inr4ssh._src.operators.finite_diff import calculate_gradient, calculate_laplacian\n",
    "from inr4ssh._src.preprocess.subset import temporal_subset, spatial_subset\n",
    "from inr4ssh._src.preprocess.coords import (\n",
    "    correct_coordinate_labels,\n",
    "    correct_longitude_domain,\n",
    ")\n",
    "from inr4ssh._src.data.ssh_obs import load_ssh_altimetry_data_train\n",
    "\n",
    "from inr4ssh._src.preprocess.coords import correct_coordinate_labels\n",
    "\n",
    "# from inr4ssh._src.preprocess.\n",
    "from inr4ssh._src.viz.movie import create_movie\n",
    "from inr4ssh._src.metrics.psd import psd_isotropic\n",
    "from inr4ssh._src.viz.psd.isotropic import plot_psd_isotropic\n",
    "from inr4ssh._src.viz.obs import plot_obs_demo\n",
    "from inr4ssh._src.metrics.psd import psd_spacetime, psd_spacetime_dask\n",
    "from inr4ssh._src.viz.psd.spacetime import (\n",
    "    plot_psd_spacetime_wavelength,\n",
    "    plot_psd_spacetime_wavenumber,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mkdir independent_data\n",
    "mkdir independent_data/altika\n",
    "mkdir independent_data/altika/2015\n",
    "mv 2015/independent_data/altika/dt_global_al* independent_data/altika/2015\n",
    "mkdir independent_data/altika/2016\n",
    "mv 2016/independent_data/altika/dt_global_al* independent_data/altika/2016\n",
    "mkdir independent_data/altika/2017\n",
    "mv 2017/independent_data/altika/dt_global_al* independent_data/altika/2017\n",
    "mkdir independent_data/altika/2018\n",
    "mv 2018/independent_data/altika/dt_global_al* independent_data/altika/2018\n",
    "mkdir independent_data/altika/2019\n",
    "mv 2019/independent_data/altika/dt_global_al* independent_data/altika/2019\n",
    "```\n",
    "\n",
    "```bash\n",
    "mkdir independent_data/sentinel3b\n",
    "mkdir independent_data/sentinel3b/2018\n",
    "mv 2018/independent_data/sentinel3b/dt_global_s3b_phy_l3* independent_data/sentinel3b/2018\n",
    "mkdir independent_data/sentinel3b/2019\n",
    "mv 2019/independent_data/sentinel3b/dt_global_s3b_phy_l3* independent_data/sentinel3b/2019\n",
    "```\n",
    "\n",
    "```bash\n",
    "mkdir grid\n",
    "mkdir grid/2015\n",
    "mv 2015/grid/dt_upd_global_merged_msla* grid/2015\n",
    "mkdir grid/2016\n",
    "mv 2016/grid/dt_upd_global_merged_msla* grid/2016\n",
    "mkdir grid/2017\n",
    "mv 2017/grid/dt_upd_global_merged_msla* grid/2017\n",
    "mkdir grid/2018\n",
    "mv 2018/grid/dt_upd_global_merged_msla* grid/2018\n",
    "mkdir grid/2019\n",
    "mv 2019/grid/dt_upd_global_merged_msla* grid/2019\n",
    "```\n",
    "\n",
    "```bash\n",
    "rm -rf 2015 2016 2017 2018 2019\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "1. We will get filenames!\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.data.dc23a import DC23aDataFiles\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"/Volumes/EMANS_HDD/data/dc23a_ose/raw/data_emmanuel\")\n",
    "\n",
    "!ls $path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init class\n",
    "data = DC23aDataFiles(path=path_data)\n",
    "\n",
    "# get altimeters (train, evaluation, all)\n",
    "altimeters = data.get_altimeters(\"train\")\n",
    "print(altimeters)\n",
    "\n",
    "altimeters = data.get_altimeters(\"evaluation\")\n",
    "print(altimeters)\n",
    "\n",
    "altimeters = data.get_altimeters(\"all\")\n",
    "print(altimeters)\n",
    "\n",
    "altimeters = data.get_altimeters(\"grid\")\n",
    "print(altimeters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specific file (altimeter=c2, year=2015)\n",
    "files = data.files_from_str(\"c2\", \"2015\")\n",
    "print(len(files))\n",
    "\n",
    "# get specific file (altimeter=c2)\n",
    "files = data.files_from_str(\"c2\")\n",
    "print(len(files))\n",
    "\n",
    "# get specific list of files (altimeters=[\"c2\", \"j2\"], year=[\"2015\", \"2016\"])\n",
    "files = data.files_from_list([\"c2\", \"j2\"], [\"2015\", \"2016\"])\n",
    "print(len(files))\n",
    "\n",
    "files = data.files_from_list([\"altika\", \"c2\"], [\"2015\", \"2017\", \"2018\"])\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train/Valid/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files\n",
    "all_files = data.files_all()\n",
    "print(len(all_files))\n",
    "assert 11_041 == len(all_files)\n",
    "\n",
    "# get files (independent data)\n",
    "files_train = data.train_files_all()\n",
    "print(len(files_train))\n",
    "assert 6_988 == len(files_train)\n",
    "\n",
    "# get files (dependent data)\n",
    "files_valid = data.valid_files_all()\n",
    "print(len(files_valid))\n",
    "assert 2_227 == len(files_valid)\n",
    "\n",
    "# get files (grid data)\n",
    "files_grid = data.grid_files_all()\n",
    "print(len(files_grid))\n",
    "assert 1_826 == len(files_grid)\n",
    "\n",
    "assert len(files_grid) + len(files_valid) + len(files_train) == len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"/Volumes/EMANS_HDD/data/dc23a_ose/raw/data_emmanuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data\n",
    "\n",
    "For this, we have some observations over the entire globe for the years\n",
    "2015-2019 (5 years)\n",
    "\n",
    "We take some 9 specific altimetry tracks:\n",
    "\n",
    "* c2\n",
    "* h2a\n",
    "* h2ag\n",
    "* h2b\n",
    "* j2\n",
    "* j2g\n",
    "* j2n\n",
    "* j3\n",
    "* s3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.preprocess.spatial import convert_lon_360_180\n",
    "from inr4ssh._src.preprocess.coords import correct_coordinate_labels\n",
    "\n",
    "# get specific file (altimeter=c2, year=2015)\n",
    "files = data.files_from_str(\"c2\", \"2015\")\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "\n",
    "    # check\n",
    "    x = correct_coordinate_labels(x)\n",
    "\n",
    "    # convert\n",
    "    x[\"longitude\"] = convert_lon_360_180(x.longitude)\n",
    "\n",
    "    #\n",
    "    x = x.sel(time=slice(np.datetime64(\"2015-02-01\"), np.datetime64(\"2015-03-01\")))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "ds_data = xr.open_mfdataset(files, preprocess=preprocess, engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"nbytes: {ds_data.nbytes / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specific file (altimeter=c2)\n",
    "files = data.files_from_str(\"c2\")\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
