{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSSE 2023a - Global Altimetry Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".root\"])\n",
    "\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "\n",
    "from inr4ssh._src.operators.finite_diff import calculate_gradient, calculate_laplacian\n",
    "from inr4ssh._src.preprocess.subset import temporal_subset, spatial_subset\n",
    "from inr4ssh._src.preprocess.coords import (\n",
    "    correct_coordinate_labels,\n",
    "    correct_longitude_domain,\n",
    ")\n",
    "from inr4ssh._src.data.ssh_obs import load_ssh_altimetry_data_train\n",
    "\n",
    "from inr4ssh._src.preprocess.coords import correct_coordinate_labels\n",
    "\n",
    "# from inr4ssh._src.preprocess.\n",
    "from inr4ssh._src.viz.movie import create_movie\n",
    "from inr4ssh._src.metrics.psd import psd_isotropic\n",
    "from inr4ssh._src.viz.psd.isotropic import plot_psd_isotropic\n",
    "from inr4ssh._src.viz.obs import plot_obs_demo\n",
    "from inr4ssh._src.metrics.psd import psd_spacetime, psd_spacetime_dask\n",
    "from inr4ssh._src.viz.psd.spacetime import (\n",
    "    plot_psd_spacetime_wavelength,\n",
    "    plot_psd_spacetime_wavenumber,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mkdir independent_data\n",
    "mkdir independent_data/altika\n",
    "mkdir independent_data/altika/2015\n",
    "mv 2015/independent_data/altika/dt_global_al* independent_data/altika/2015\n",
    "mkdir independent_data/altika/2016\n",
    "mv 2016/independent_data/altika/dt_global_al* independent_data/altika/2016\n",
    "mkdir independent_data/altika/2017\n",
    "mv 2017/independent_data/altika/dt_global_al* independent_data/altika/2017\n",
    "mkdir independent_data/altika/2018\n",
    "mv 2018/independent_data/altika/dt_global_al* independent_data/altika/2018\n",
    "mkdir independent_data/altika/2019\n",
    "mv 2019/independent_data/altika/dt_global_al* independent_data/altika/2019\n",
    "```\n",
    "\n",
    "```bash\n",
    "mkdir independent_data/sentinel3b\n",
    "mkdir independent_data/sentinel3b/2018\n",
    "mv 2018/independent_data/sentinel3b/dt_global_s3b_phy_l3* independent_data/sentinel3b/2018\n",
    "mkdir independent_data/sentinel3b/2019\n",
    "mv 2019/independent_data/sentinel3b/dt_global_s3b_phy_l3* independent_data/sentinel3b/2019\n",
    "```\n",
    "\n",
    "```bash\n",
    "mkdir grid\n",
    "mkdir grid/2015\n",
    "mv 2015/grid/dt_upd_global_merged_msla* grid/2015\n",
    "mkdir grid/2016\n",
    "mv 2016/grid/dt_upd_global_merged_msla* grid/2016\n",
    "mkdir grid/2017\n",
    "mv 2017/grid/dt_upd_global_merged_msla* grid/2017\n",
    "mkdir grid/2018\n",
    "mv 2018/grid/dt_upd_global_merged_msla* grid/2018\n",
    "mkdir grid/2019\n",
    "mv 2019/grid/dt_upd_global_merged_msla* grid/2019\n",
    "```\n",
    "\n",
    "```bash\n",
    "rm -rf 2015 2016 2017 2018 2019\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "1. We will get filenames!\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import config_dict\n",
    "\n",
    "config = config_dict.ConfigDict()\n",
    "\n",
    "# altimetry configuration\n",
    "config.altimeters = altimeters = config_dict.ConfigDict()\n",
    "altimeters.dependent = [\"c2\", \"h2a\", \"h2ag\", \"h2b\", \"j2\", \"j2g\", \"j2n\", \"j3\", \"s3a\"]\n",
    "\n",
    "altimeters.independent = [\n",
    "    \"sentinel3b\",\n",
    "    \"altika\",\n",
    "]\n",
    "\n",
    "config.altimeters.years = [\"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "from inr4ssh._src.files import list_all_files, get_subset_elements\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DC23aData:\n",
    "    path: str\n",
    "    altimeters = config_dict.ConfigDict()\n",
    "    altimeters.dependent = [\"c2\", \"h2a\", \"h2ag\", \"h2b\", \"j2\", \"j2g\", \"j2n\", \"j3\", \"s3a\"]\n",
    "    altimeters.independent = [\n",
    "        \"sentinel3b\",\n",
    "        \"altika\",\n",
    "    ]\n",
    "    years = [\"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "\n",
    "    def get_altimeters(self, stage: str = \"train\"):\n",
    "        if stage == \"train\":\n",
    "            return self.altimeters.dependent\n",
    "        elif stage == \"evaluation\":\n",
    "            return self.altimeters.independent\n",
    "        elif stage == \"all\":\n",
    "            return self.altimeters.dependent + self.altimeters.independent\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized stage: {stage}\")\n",
    "\n",
    "    def files_all(self):\n",
    "        return list_all_files(path_data)\n",
    "\n",
    "    def files_from_str(self, altimeter: str, year: Optional[str] = None):\n",
    "        files = self.files_all()\n",
    "        print(len(files))\n",
    "        # TODO: ext=f\"{altimeter}/{year}/**/*\"\n",
    "        files = get_subset_files_str(files, altimeter)\n",
    "        print(len(files))\n",
    "        if year is not None:\n",
    "            files = get_subset_files_str(files, year)\n",
    "        return files\n",
    "\n",
    "    def files_from_list(self, altimeters: List[str], years: Optional[List[str]] = None):\n",
    "        files = self.files_all()\n",
    "        print(len(files))\n",
    "        files = get_subset_files_list(files, altimeters)\n",
    "        print(len(files))\n",
    "        if years is not None:\n",
    "            files = get_subset_files_list(files, years)\n",
    "        return files\n",
    "\n",
    "    def train_files_all(self):\n",
    "        return self.files_from_list(altimeters=self.altimeters.dependent)\n",
    "\n",
    "    def grid_files_all(self):\n",
    "        return self.files_from_str(altimeter=\"grid\")\n",
    "\n",
    "    def valid_files_all(self):\n",
    "        return self.files_from_list(altimeters=self.get_altimeters(\"evaluation\"))\n",
    "\n",
    "\n",
    "def get_subset_files_str(files_list, element: str = \"c2\"):\n",
    "\n",
    "    assert isinstance(element, str)\n",
    "\n",
    "    files = list(filter(lambda ifile: element in str(ifile), files_list))\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_subset_files_list(files_list, elements: List[str]):\n",
    "\n",
    "    assert isinstance(elements, list)\n",
    "\n",
    "    files = list()\n",
    "    for ielement in elements:\n",
    "        files += get_subset_files_str(files_list, ielement)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"/Volumes/EMANS_HDD/data/dc23a_ose/raw/data_emmanuel\")\n",
    "\n",
    "!ls $path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init class\n",
    "data = DC23aData(path=path_data)\n",
    "\n",
    "# get all files\n",
    "all_files = data.files_all()\n",
    "print(len(all_files))\n",
    "\n",
    "assert 11_041 == len(all_files)\n",
    "\n",
    "# get altimeters (train, evaluation, all)\n",
    "altimeters = data.get_altimeters(\"train\")\n",
    "print(altimeters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files (independent data)\n",
    "files_train = data.train_files_all()\n",
    "print(len(files_train))\n",
    "\n",
    "data.get_altimeters(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files_train:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files (independent data)\n",
    "files_train = data.train_files_all()\n",
    "print(len(files_train))\n",
    "assert 6_988 == len(files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files (independent data)\n",
    "files_train = data.train_files_all()\n",
    "print(len(files_train))\n",
    "assert 6_988 == len(files_train)\n",
    "\n",
    "# files_test = data.valid_files_all()\n",
    "# print(len(files_test))\n",
    "# assert 2_227 == len(files_test)\n",
    "\n",
    "\n",
    "files_grid = data.grid_files_all()\n",
    "print(len(files_grid))\n",
    "assert 1_826 == len(files_grid)\n",
    "#\n",
    "# assert len(files_grid) + len(files_train) + len(files_test) == len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_grid), len(files_train), len(files_test), len(files_grid) + len(\n",
    "    files_train\n",
    ") + len(files_test), len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specific file (altimeter=c2, year=2015)\n",
    "files = data.files_from_str(\"sentinel3b\")\n",
    "print(len(files))\n",
    "\n",
    "# get specific list of files (altimeters=[\"c2\", \"j2\"], year=[\"2015\", \"2016\"])\n",
    "files = data.files_from_list([\"c2\", \"j2\"], [\"2015\", \"2016\"])\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train/Valid/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Volumes/EMANS_HDD/data/dc23a_ose/raw/data_emmanuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"/Volumes/EMANS_HDD/data/dc23a_ose/raw/data_emmanuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data\n",
    "\n",
    "For this, we have some observations over the entire globe for the years\n",
    "2015-2019 (5 years)\n",
    "\n",
    "We take some 9 specific altimetry tracks:\n",
    "\n",
    "* c2\n",
    "* h2a\n",
    "* h2ag\n",
    "* h2b\n",
    "* j2\n",
    "* j2g\n",
    "* j2n\n",
    "* j3\n",
    "* s3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training = path_data.joinpath(\"NON_independent_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $path_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"/Volumes/EMANS_HDD/data/dc23a_ose/raw/data_emmanuel/independent_data\")\n",
    "len(list_all_files(path_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "\n",
    "def get_altimetry_files_query(altimeter: str, year: str):\n",
    "\n",
    "    return list_all_files(path_training, ext=f\"{altimeter}/{year}/**/*\")\n",
    "\n",
    "\n",
    "def get_altimetry_files_dict(\n",
    "    altimeters: List[str] = [\"c2\"], years: List[str] = [\"2017\"]\n",
    "):\n",
    "\n",
    "    files = {}\n",
    "    for ialtimeter in altimeters:\n",
    "        files[ialtimeter] = {}\n",
    "        for iyear in years:\n",
    "            ifiles = get_altimetry_files_query(altimeter=ialtimeter, year=iyear)\n",
    "            if len(ifiles) > 0:\n",
    "                files[ialtimeter][iyear] = ifiles\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_altimetry_files_list(\n",
    "    altimeters: List[str] = [\"c2\"], years: List[str] = [\"2017\"]\n",
    "):\n",
    "\n",
    "    list_of_queries = list(itertools.product(altimeters, years))\n",
    "\n",
    "    files = list()\n",
    "\n",
    "    for iquery in tqdm(list_of_queries):\n",
    "        ifiles = get_altimetry_files_query(altimeter=iquery[0], year=iquery[1])\n",
    "\n",
    "        files += ifiles\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_altimetry_files_query(\n",
    "    config.altimeters.dependent[0], config.altimeters.years[0]\n",
    ")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_altimetry_files_list(config.altimeters.dependent, config.altimeters.years)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\"c2\"]\n",
    "\n",
    "\n",
    "def get_subset_files_str(files_list, element: str = \"c2\"):\n",
    "\n",
    "    assert isinstance(element, str)\n",
    "\n",
    "    files = list(filter(lambda ifile: element in str(ifile), files_list))\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_subset_files_list(files_list, elements: List[str]):\n",
    "\n",
    "    assert isinstance(elements, list)\n",
    "\n",
    "    files = list()\n",
    "    for ielement in elements:\n",
    "        files += get_subset_files_str(files_list, ielement)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_files = get_subset_files_str(files, \"c2\")\n",
    "c2_2015_files = get_subset_files_str(c2_files, \"2015\")\n",
    "len(c2_files), len(c2_2015_files),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_files = get_subset_files_list(files, [\"c2\"])\n",
    "c2_2015_files = get_subset_files_list(c2_files, [\"2015\"])\n",
    "len(c2_files), len(c2_2015_files),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_files_ = get_subset_files_list(files, [\"c2\"])\n",
    "c2_2015_files_ = get_subset_files_list(files, [\"2015\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"h2a\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = list_all_files(path_training, ext=f\"{altimeter}/{year}/**/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_obs = xr.open_mfdataset(training_files)\n",
    "ds_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in subdirectories\n",
    "training_files = list_all_files(path_training, ext=\"c2/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset elements (c2)\n",
    "files_c2 = get_subset_elements([\"c2\"], training_files)\n",
    "\n",
    "len(files_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
