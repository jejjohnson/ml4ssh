{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d67b99-71be-4f66-9397-b15b60ee0226",
   "metadata": {},
   "source": [
    "\n",
    "# NerF + QG Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59583528-46e3-4e59-99c6-338029736d60",
   "metadata": {},
   "source": [
    "The full QG equation is given by:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\partial_t q + \\det \\boldsymbol{J}(q, \\psi) &= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $q=\\nabla^2 \\psi$\n",
    "* $\\det \\boldsymbol{J}(q, \\psi)=\\partial_x q\\partial_y\\psi - \\partial_y q\\partial_x\\psi$.\n",
    "\n",
    "We are interested in finding some NerF method that can take in the spatial-temporal coordinates, $\\mathbf{x}_\\phi$, and output a vector corresponding to the PV and stream function, $\\psi$, i.e. $\\mathbf{y}_\\text{obs}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_\\text{obs} = \\boldsymbol{f_\\theta}(\\mathbf{x}_\\phi) + \\epsilon, \\hspace{5mm}\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "We use a SIREN network which is a fully connected neural network with the $sin$ activation function.\n",
    "\n",
    "* **Data Inputs**: `256x256x11`\n",
    "* **Data Ouputs**: `2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d850f86-a38d-41f6-972c-4ecb70a3af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pyprojroot import here\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".root\"])\n",
    "exp = here(\n",
    "    relative_project_path=root.joinpath(\"experiments/dc21a\"), project_files=[\".local\"]\n",
    ")\n",
    "\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))\n",
    "sys.path.append(str(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from ml_collections import config_dict\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from inr4ssh._src.datamodules.osse_2020a import AlongTrackDataModule\n",
    "\n",
    "pl.seed_everything(123)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975fa36-64cc-4848-938a-3c1cdd14b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml_collections import config_dict\n",
    "\n",
    "# cfg = config_dict.ConfigDict()\n",
    "\n",
    "# # logging args\n",
    "# cfg.log = config_dict.ConfigDict()\n",
    "# cfg.log.mode = \"online\" #\"disabled\"\n",
    "# cfg.log.project =\"inr4ssh\"\n",
    "# cfg.log.entity = \"ige\"\n",
    "# cfg.log.log_dir = \"/Users/eman/code_projects/logs/\"\n",
    "# cfg.log.resume = False\n",
    "\n",
    "# # data args\n",
    "# cfg.data = config_dict.ConfigDict()\n",
    "# cfg.data.data_dir =  f\"/Users/eman/code_projects/torchqg/data/qgsim_simple_128x128.nc\"\n",
    "\n",
    "# # preprocessing args\n",
    "# cfg.pre = config_dict.ConfigDict()\n",
    "# cfg.pre.noise = 0.01\n",
    "# cfg.pre.dt = 1.0\n",
    "# cfg.pre.time_min = 500\n",
    "# cfg.pre.time_max = 511\n",
    "# cfg.pre.seed = 123\n",
    "\n",
    "# # train/test args\n",
    "# cfg.split = config_dict.ConfigDict()\n",
    "# cfg.split.train_prct = 0.9\n",
    "\n",
    "# # dataloader args\n",
    "# cfg.dl = config_dict.ConfigDict()\n",
    "# cfg.dl.batchsize_train = 2048\n",
    "# cfg.dl.batchsize_val = 1_000\n",
    "# cfg.dl.batchsize_test = 5_000\n",
    "# cfg.dl.batchsize_predict = 10_000\n",
    "# cfg.dl.num_workers = 0\n",
    "# cfg.dl.pin_memory = False\n",
    "\n",
    "# # loss arguments\n",
    "# cfg.loss = config_dict.ConfigDict()\n",
    "# cfg.loss.qg = True\n",
    "# cfg.loss.alpha = 1e-4\n",
    "\n",
    "# # optimizer args\n",
    "# cfg.optim = config_dict.ConfigDict()\n",
    "# cfg.optim.warmup = 10\n",
    "# cfg.optim.num_epochs = 100\n",
    "# cfg.optim.learning_rate = 1e-4\n",
    "\n",
    "# # trainer args\n",
    "# cfg.trainer = config_dict.ConfigDict()\n",
    "# cfg.trainer.accelerator = None\n",
    "# cfg.trainer.devices = 1\n",
    "# cfg.trainer.grad_batches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac47ef1-8d2d-4e12-8f17-fc53fe4a5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inr4ssh._src.io import transform_dict\n",
    "\n",
    "# cfg = get_config()\n",
    "\n",
    "# cfg.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788b8f2-9941-4da8-b906-038115cb8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_logger = WandbLogger(\n",
    "#     config=cfg.to_dict(),\n",
    "#     mode=\"offline\",  # cfg.log.mode,\n",
    "#     project=cfg.log.project,\n",
    "#     entity=cfg.log.entity,\n",
    "#     dir=cfg.log.log_dir,\n",
    "#     resume=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Users/eman/code_projects/torchqg/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4858b20-4c08-496b-aa14-64d72cc6b65f",
   "metadata": {},
   "source": [
    "## Data Module\n",
    "\n",
    "Now we will put all of the preprocessing routines together. This is **very important** for a few reasons:\n",
    "\n",
    "1. It collapses all of the operations in a modular way\n",
    "2. It makes it reproducible for the next people\n",
    "3. It makes it very easy for the PyTorch-Lightning framework down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da06ade-90f7-41ad-9165-6c05a876f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import config_dict\n",
    "\n",
    "config = config_dict.ConfigDict()\n",
    "\n",
    "# data directory\n",
    "config.data = data = config_dict.ConfigDict()\n",
    "data.dataset_dir = \"/Volumes/EMANS_HDD/data/dc20a_osse/test/ml/nadir1.nc\"\n",
    "\n",
    "# preprocessing\n",
    "config.preprocess = config_dict.ConfigDict()\n",
    "config.preprocess.subset_time = subset_time = config_dict.ConfigDict()\n",
    "subset_time.subset_time = True\n",
    "subset_time.time_min = \"2012-10-22\"\n",
    "subset_time.time_max = \"2012-12-02\"\n",
    "\n",
    "config.preprocess.subset_spatial = subset_spatial = config_dict.ConfigDict()\n",
    "subset_spatial.subset_spatial = True\n",
    "subset_spatial.lon_min = -65.0\n",
    "subset_spatial.lon_max = -55.0\n",
    "subset_spatial.lat_min = 33.0\n",
    "subset_spatial.lat_max = 43.0\n",
    "\n",
    "# transformations\n",
    "config.preprocess.transform = transform = config_dict.ConfigDict()\n",
    "transform.time_transform = \"minmax\"\n",
    "transform.time_min = \"2011-01-01\"\n",
    "transform.time_max = \"2013-12-12\"\n",
    "\n",
    "# train/valid arguments\n",
    "config.traintest = traintest = config_dict.ConfigDict()\n",
    "traintest.train_prct = 0.9\n",
    "traintest.seed = 42\n",
    "\n",
    "# dataloader\n",
    "config.dataloader = dataloader = config_dict.ConfigDict()\n",
    "# train dataloader\n",
    "dataloader.batchsize_train = 32\n",
    "dataloader.num_workers_train = 2\n",
    "dataloader.shuffle_train = True\n",
    "dataloader.pin_memory_train = False\n",
    "# valid dataloader\n",
    "dataloader.batchsize_valid = 32\n",
    "dataloader.num_workers_valid = 2\n",
    "dataloader.shuffle_valid = False\n",
    "dataloader.pin_memory_valid = False\n",
    "# predict dataloader\n",
    "dataloader.batchsize_predict = 32\n",
    "dataloader.num_workers_predict = 4\n",
    "dataloader.shuffle_predict = False\n",
    "dataloader.pin_memory_predict = False\n",
    "\n",
    "# EVALUATION\n",
    "config.evaluation = evaluation = config_dict.ConfigDict()\n",
    "evaluation.lon_min = -65.0\n",
    "evaluation.lon_max = -55.0\n",
    "evaluation.dlon = 0.1\n",
    "evaluation.lat_min = 33.0\n",
    "evaluation.lat_max = 43.0\n",
    "evaluation.dlat = 0.1\n",
    "\n",
    "evaluation.time_min = \"2012-10-22\"\n",
    "evaluation.time_max = \"2012-12-02\"\n",
    "evaluation.dt_freq = 1\n",
    "evaluation.dt_unit = \"D\"\n",
    "# , get_demo_config\n",
    "\n",
    "# config = get_demo_config()\n",
    "\n",
    "config.preprocess.subset_spatial.subset_spatial = True\n",
    "config.preprocess.subset_time.subset_time = True\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da7217-f0a7-42b9-9351-db849446c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data module\n",
    "dm = AlongTrackDataModule(\n",
    "    root=None,\n",
    "    config=config,\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "# initialize datamodule params\n",
    "dm.setup()\n",
    "\n",
    "# initialize dataloaders\n",
    "train_ds = dm.train_dataloader()\n",
    "\n",
    "valid_ds = dm.val_dataloader()\n",
    "\n",
    "predict_ds = dm.predict_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924f943-f3bd-481c-9e20-e1fc9403aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "data = dm.ds_train[:10]\n",
    "\n",
    "data[\"spatial\"].shape, data[\"temporal\"].shape, data[\"output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d925a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = torch.cat([data[\"spatial\"], data[\"temporal\"]], dim=1)\n",
    "y_init = data[\"output\"]\n",
    "x_init.shape, y_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0beae39",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "**Spatial**:\n",
    "\n",
    "> We want to transform this from degrees to radians\n",
    "\n",
    "\n",
    "**Temporal**:\n",
    "\n",
    "> We want to transform this from time to sines and cosines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a68f60-19d7-439e-988b-8a99263ee269",
   "metadata": {},
   "source": [
    "## NerF\n",
    "\n",
    "This standard Neural Fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a5668-1ac3-440c-bc8c-5fbbc485ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inr4ssh._src.models.siren import Siren, SirenNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f1b7f-e81c-4f96-a310-f766872f0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = x_init.shape[1]\n",
    "dim_hidden = 256\n",
    "dim_out = y_init.shape[1]\n",
    "num_layers = 4\n",
    "w0 = 1.0\n",
    "w0_initial = 30.0\n",
    "c = 6.0\n",
    "final_activation = None  # nn.Sigmoid()\n",
    "\n",
    "net = SirenNet(\n",
    "    dim_in=dim_in,\n",
    "    dim_hidden=dim_hidden,\n",
    "    dim_out=dim_out,\n",
    "    num_layers=num_layers,\n",
    "    w0=w0,\n",
    "    w0_initial=w0_initial,\n",
    "    c=c,\n",
    "    final_activation=final_activation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8b3c9-60a0-4cea-89f9-8f16daf2b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(x_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7ab29-f515-465d-a4c5-1f786806008e",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5ee8c-a204-48dc-a47f-fbc66d88646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from functools import partial\n",
    "from typing import Dict, Any, cast\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35508e0c-bdf9-4909-b898-208a2617daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class INRModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        spatial_transform=None,\n",
    "        temporal_transform=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.hyperparams = cast(Dict[str, Any], self.hparams)\n",
    "        self.loss_data = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _data_loss(self, batch):\n",
    "        x, y = self._extract_spacetime(batch=batch, outputs=True)\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        # data loss function\n",
    "        loss = self.loss_data(y, pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _extract_spacetime(self, batch, outputs=False):\n",
    "\n",
    "        x_space, x_time = batch[\"spatial\"], batch[\"temporal\"]\n",
    "        x = torch.cat([x_space, x_time], dim=1)\n",
    "\n",
    "        if outputs:\n",
    "            return x, batch[\"output\"]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # loss function\n",
    "        loss = self._data_loss(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        # loss function\n",
    "        loss = self._data_loss(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        # loss function\n",
    "        loss = self._data_loss(batch)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # output\n",
    "        x = self._extract_spacetime(batch=batch, outputs=False)\n",
    "\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # configure optimizer\n",
    "        optimizer = Adam(\n",
    "            self.model.parameters(), lr=self.hyperparams.get(\"learning_rate\", 1e-4)\n",
    "        )\n",
    "\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer,\n",
    "            warmup_epochs=self.hyperparams.get(\"warmup\", 10),\n",
    "            max_epochs=self.hyperparams.get(\"num_epochs\", 100),\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "warmup = 1\n",
    "num_epochs = 5\n",
    "\n",
    "learn = INRModel(\n",
    "    model=net,\n",
    "    loss_data=nn.MSELoss(\"mean\"),\n",
    "    learning_rate=learning_rate,\n",
    "    warmup=warmup,\n",
    "    num_epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe37d1-9ba0-4c06-855d-2eacb9280d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = \"ige/inr4ssh/1st3rtl0\"\n",
    "# model_path = \"checkpoints/epoch=990-step=39640.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641689c3-858f-47d3-8a5a-d0a5f51d3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inr4ssh._src.io import get_wandb_config, get_wandb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a42b7-4c8b-4bc8-8615-bed4076bad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = get_wandb_model(run_path, model_path)\n",
    "# best_model.download(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614a086-9047-409a-bca0-a6c5f5397560",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb6f69-6ac9-4c63-92c3-5cba761c4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import TQDMProgressBar, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49aef1-e25b-439e-b7ba-32bfa9156080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b3719-950a-4451-854f-7e1be116d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcda2a4-ed6a-4f00-a5f7-c91a370a33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cb = ModelCheckpoint(\n",
    "\n",
    "#     dirpath=str(Path(wandb_logger.experiment.dir).joinpath(\"checkpoints\")),\n",
    "#     monitor=\"val_loss\",\n",
    "#     mode=\"min\",\n",
    "#     save_top_k=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d01235-05c7-4419-bbdf-c297290d810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # model_cb,\n",
    "    TQDMProgressBar(refresh_rate=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac691f0e-8563-466b-ba03-aa5e036a6937",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d74bf-df3e-4040-ade6-3ed1f60b2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load(best_model.name, map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac1925-e2cf-4f54-9197-5d245057f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e95d4-5df7-4a3c-a10a-a7bb2541e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwargs,\n",
    "# net = SirenNet(**kwargs)\n",
    "# net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764224d-c5f7-4811-bc90-95a7e52d2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = INRModel.load_from_checkpoint(\n",
    "#     best_model.name,\n",
    "#     model=net,\n",
    "#     loss_data=nn.MSELoss(\"mean\"),\n",
    "#     reg_pde=reg_loss,\n",
    "#     learning_rate=cfg.optim.learning_rate,\n",
    "#     warmup=cfg.optim.warmup,\n",
    "#     num_epochs=cfg.optim.num_epochs,\n",
    "#     alpha=cfg.loss.alpha,\n",
    "#     qg=cfg.loss.qg,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94dae0-3f14-471b-bb82-5206b862d5ad",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58be52-50e3-4072-82c4-7ef17fb24fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = \"cpu\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    min_epochs=1,\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=accelerator,\n",
    "    # devices=cfg.trainer.devices,\n",
    "    enable_progress_bar=True,\n",
    "    # logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    # accumulate_grad_batches=cfg.trainer.grad_batches,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd7117-e4db-426f-b470-bfb22c424570",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889c892-20c6-4446-8818-f8b7a6df9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    learn,\n",
    "    datamodule=dm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87e6b4-1d97-4d5d-a00b-2c14b28677e0",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7dc94-9401-46b7-99dd-9643352951e0",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.lon_min = -65.0\n",
    "evaluation.lon_max = -55.0\n",
    "evaluation.dlon = 0.1\n",
    "evaluation.lat_min = 33.0\n",
    "evaluation.lat_max = 43.0\n",
    "evaluation.dlat = 0.1\n",
    "\n",
    "evaluation.time_min = \"2012-10-22\"\n",
    "evaluation.time_max = \"2012-12-02\"\n",
    "evaluation.dt_freq = 1\n",
    "evaluation.dt_unit = \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd50d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds_dir = Path(\n",
    "    \"/Volumes/EMANS_HDD/data/dc20a_osse/raw/dc_ref/NATL60-CJM165_GULFSTREAM*\"\n",
    ")\n",
    "eval_ds_dir = \"/Volumes/EMANS_HDD/data/dc20a_osse/raw/dc_ref/NATL60-CJM165_GULFSTREAM*\"\n",
    "ds = xr.open_mfdataset(eval_ds_dir, engine=\"netcdf4\")\n",
    "\n",
    "from inr4ssh._src.preprocess.coords import correct_coordinate_labels\n",
    "\n",
    "\n",
    "time_min = evaluation.time_min\n",
    "time_max = evaluation.time_max\n",
    "lon_min = evaluation.lon_min\n",
    "lon_max = evaluation.lon_max\n",
    "lat_min = evaluation.lat_min\n",
    "lat_max = evaluation.lat_max\n",
    "\n",
    "ds = (\n",
    "    ds.sel(\n",
    "        time=slice(time_min, time_max),\n",
    "        lon=slice(lon_min, lon_max),\n",
    "        lat=slice(lat_min, lat_max),\n",
    "        drop=True,\n",
    "    )\n",
    "    .resample(time=\"1D\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "ds = correct_coordinate_labels(ds)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5adf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x, y, z = np.meshgrid(\n",
    "    ds.coords[\"longitude\"].data, ds.coords[\"latitude\"].data, ds.coords[\"time\"].data\n",
    ")\n",
    "\n",
    "\n",
    "ds_ref_coords = pd.DataFrame(\n",
    "    {\"longitude\": x.flatten(), \"latitude\": y.flatten(), \"time\": z.flatten()}\n",
    ")\n",
    "\n",
    "from inr4ssh._src.datasets.alongtrack import AlongTrackDataset\n",
    "from inr4ssh._src.transforms.dataset import transform_factory\n",
    "\n",
    "transform = transform_factory(config.preprocess.transform)\n",
    "ds_eval = AlongTrackDataset(\n",
    "    ds_ref_coords, spatial_columns=[\"longitude\", \"latitude\"], temporal_columns=[\"time\"]\n",
    ")\n",
    "dl_eval = torch.utils.data.DataLoader(\n",
    "    dm.ds_predict,\n",
    "    batch_size=config.dataloader.batchsize_predict,\n",
    "    shuffle=config.dataloader.shuffle_predict,\n",
    "    num_workers=config.dataloader.num_workers_predict,\n",
    "    pin_memory=config.dataloader.pin_memory_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_eval), len(dm.ds_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "predictions = trainer.predict(learn, dataloaders=dl_eval, return_predictions=True)\n",
    "predictions = torch.cat(predictions)\n",
    "t1 = time.time() - t0\n",
    "print(f\"Time Taken: {t1:.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457bdd95",
   "metadata": {},
   "source": [
    "---\n",
    "**DATA**\n",
    "\n",
    "* convert this reference grid to `lat,lon,time,sossheig`\n",
    "* create dataloader\n",
    "* Make predictions\n",
    "* Create xr.dataset from predictions\n",
    "\n",
    "---\n",
    "**Metrics**\n",
    "\n",
    "* RMSE Metrics\n",
    "* PSD Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(self.config.data.dataset_dir)\n",
    "\n",
    "# correct the labels\n",
    "logger.info(\"Correcting labels...\")\n",
    "ds = correct_coordinate_labels(ds)\n",
    "\n",
    "logger.info(\"Sorting array by time...\")\n",
    "ds = ds.sortby(\"time\")\n",
    "\n",
    "# temporal subset\n",
    "if self.config.preprocess.subset_time.subset_time:\n",
    "    logger.info(\"Subsetting temporal...\")\n",
    "    time_min = self.config.preprocess.subset_time.time_min\n",
    "    time_max = self.config.preprocess.subset_time.time_max\n",
    "    logger.debug(f\"Time Min: {time_min} | Time Max: {time_max}...\")\n",
    "    ds = ds.sel(time=slice(time_min, time_max), drop=True)\n",
    "\n",
    "# spatial subset\n",
    "if self.config.preprocess.subset_spatial.subset_spatial:\n",
    "    logger.info(\"Subseting spatial...\")\n",
    "    lon_min = self.config.preprocess.subset_spatial.lon_min\n",
    "    lon_max = self.config.preprocess.subset_spatial.lon_max\n",
    "    lat_min = self.config.preprocess.subset_spatial.lat_min\n",
    "    lat_max = self.config.preprocess.subset_spatial.lat_max\n",
    "    logger.debug(f\"Lon Min: {lon_min} | Lon Max: {lon_min}...\")\n",
    "    ds = ds.where(\n",
    "        (ds[\"longitude\"] >= lon_min)\n",
    "        & (ds[\"longitude\"] <= lon_max)\n",
    "        & (ds[\"latitude\"] >= lat_min)\n",
    "        & (ds[\"latitude\"] <= lat_max),\n",
    "        drop=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb782e-493c-43cb-a481-9a36bdf33045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = trainer.test(learn, dataloaders=dm.test_dataloader())\n",
    "\n",
    "# results[\"data\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923b2c1-0b0d-47de-9940-3e020d5b2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e93692-f60c-457a-b483-eb7a8da4d771",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b77091-4ca8-4084-9bc3-a2eb75ae545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "predictions = trainer.predict(learn, datamodule=dm, return_predictions=True)\n",
    "predictions = torch.cat(predictions)\n",
    "t1 = time.time() - t0\n",
    "print(f\"Time Taken: {t1:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accfbe4-5fbf-4158-8ef2-8cc3bb09c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pred = dm.create_predictions_ds(predictions)\n",
    "\n",
    "from inr4ssh._src.operators import differential_simp as diffops_simp\n",
    "\n",
    "from inr4ssh._src.operators import differential as diffops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = dm.ds_predict.create_predict_df(predictions.detach().numpy())\n",
    "ds_pred = df_pred.reset_index().set_index([\"longitude\", \"latitude\", \"time\"]).to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.predict.thin(time=4).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=4,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pred.predict.hvplot.image(x=\"Longitude\", y=\"Latitude\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e050c0e-a4a7-4385-a9a0-69f76769223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pred = dm.create_predictions_ds(predictions)\n",
    "# ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41860c7-d962-4068-b62c-74404b92dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "coords, truths, preds, grads, qs = [], [], [], [], []\n",
    "for ibatch in tqdm(dm.predict_dataloader()):\n",
    "    with torch.set_grad_enabled(True):\n",
    "        # prediction\n",
    "        ibatch[\"spatial\"] = torch.autograd.Variable(\n",
    "            ibatch[\"spatial\"].clone(), requires_grad=True\n",
    "        )\n",
    "        ibatch[\"temporal\"] = torch.autograd.Variable(\n",
    "            ibatch[\"temporal\"].clone(), requires_grad=True\n",
    "        )\n",
    "        ix = torch.cat([ibatch[\"spatial\"], ibatch[\"temporal\"]], dim=1)\n",
    "        p_pred = learn.model(ix)\n",
    "\n",
    "        # p_pred = p_pred.clone()\n",
    "        # p_pred.require_grad_ = True\n",
    "\n",
    "        # gradient\n",
    "        p_grad = diffops_simp.gradient(p_pred, ibatch[\"spatial\"])\n",
    "        # p_grad = diffops.grad(p_pred, ix)\n",
    "        # q\n",
    "        q = diffops_simp.divergence(p_grad, ibatch[\"spatial\"])\n",
    "        # q = diffops.div(p_grad, ix)\n",
    "\n",
    "    # collect\n",
    "    # truths.append(ibatch[\"output\"])\n",
    "    coords.append(ix)\n",
    "    preds.append(p_pred)\n",
    "    grads.append(p_grad)\n",
    "    qs.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = torch.cat(coords).detach().numpy()\n",
    "preds = torch.cat(preds).detach().numpy()\n",
    "# truths = torch.cat(truths).detach().numpy()\n",
    "grads = torch.cat(grads).detach().numpy()\n",
    "qs = torch.cat(qs).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = dm.ds_predict.create_predict_df(predictions.detach().numpy())\n",
    "df_pred[\"u\"] = -grads[:, 1]\n",
    "df_pred[\"v\"] = grads[:, 0]\n",
    "df_pred[\"q\"] = qs\n",
    "ds_pred = df_pred.reset_index().set_index([\"longitude\", \"latitude\", \"time\"]).to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07d577-c1dc-4e4a-bf74-3fcf4238671c",
   "metadata": {},
   "source": [
    "### Figure I: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371074d9-6e15-4cc8-9a34-d5df99116f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.q.thin(time=4).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=4,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ecdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c20d6-d0f9-413e-8d11-00f35fae2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.pred.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f6335-81a6-4ceb-949b-2662225e8a7b",
   "metadata": {},
   "source": [
    "### Figure II: Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb20ec-9944-4fb2-b531-ebe0f1277dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.thin(time=1).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=3,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ef878-2f4f-4f9e-9249-049b5ac27a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred.true.hvplot.image(x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887d598-dcc4-4691-a187-f8f334f120f8",
   "metadata": {},
   "source": [
    "### Figure III: Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5262c-2b6e-44e2-a5eb-a49d58ddcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_pred.true - ds_pred.pred).thin(time=1).plot.imshow(\n",
    "    col=\"time\",\n",
    "    robust=True,\n",
    "    col_wrap=3,\n",
    "    cmap=\"RdBu_r\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f73aa0-204b-40b3-9afc-c74803dff47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_pred.true - ds_pred.pred).hvplot.image(\n",
    "    x=\"Nx\", y=\"Ny\", width=500, height=400, cmap=\"viridis\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba845ae818c285ca2fe9389acfa2d2da9f6f964e42b65478d402ad448a072775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
